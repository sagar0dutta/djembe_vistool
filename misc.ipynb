{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Paths\n",
    "drum_dir = r\"D:\\pyspace\\Djembe\\2025\\mocap_formats\\data\\drum_onsets\"\n",
    "start_times_path = r\"D:\\pyspace\\Djembe\\2025\\mocap_formats\\data\\start_times_part12.csv\"\n",
    "\n",
    "# Load start times and keep only recordings with a defined Part 2 start\n",
    "df_times = pd.read_csv(start_times_path)\n",
    "df_p2 = df_times.dropna(subset=['start_time_p2_seconds'])\n",
    "\n",
    "for _, row in df_p2.iterrows():\n",
    "    recording = row['recording']               # e.g. \"BKO_E1_D1_01_Suku_P2\"\n",
    "    threshold = row['start_time_p2_seconds']   # float seconds\n",
    "\n",
    "    # Derive the CSV filename by stripping the \"_P2\" suffix\n",
    "    base_name = recording.rsplit('_', 1)[0]    # e.g. \"BKO_E1_D1_01_Suku\"\n",
    "    csv_path = os.path.join(drum_dir, f\"{base_name}.csv\")\n",
    "\n",
    "    if not os.path.isfile(csv_path):\n",
    "        print(f\"Warning: file not found: {csv_path}\")\n",
    "        continue\n",
    "\n",
    "    # Read the CSV\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(f\"\\nProcessing {base_name}\")\n",
    "    print(f\"Threshold: {threshold}\")\n",
    "    print(f\"Original number of rows: {len(df)}\")\n",
    "    \n",
    "    # Print column lengths before trimming\n",
    "    print(\"\\nColumn lengths before trimming:\")\n",
    "    for col in ['Dun', 'J1', 'J2']:\n",
    "        print(f\"{col}: {df[col].count()} non-NaN values\")\n",
    "    \n",
    "    # Trim each column independently\n",
    "    df['Dun'] = df['Dun'].where(df['Dun'] <= threshold)\n",
    "    df['J1'] = df['J1'].where(df['J1'] <= threshold)\n",
    "    df['J2'] = df['J2'].where(df['J2'] <= threshold)\n",
    "    \n",
    "    # Print column lengths after trimming\n",
    "    print(\"\\nColumn lengths after trimming:\")\n",
    "    for col in ['Dun', 'J1', 'J2']:\n",
    "        print(f\"{col}: {df[col].count()} non-NaN values\")\n",
    "    \n",
    "    # Save the modified dataframe\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\"Trimmed and saved: {csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import math\n",
    "\n",
    "parts_dir = r\"D:\\pyspace\\Djembe\\2025\\mocap_formats\\data\\parts\"\n",
    "output_csv = r\"D:\\pyspace\\Djembe\\2025\\mocap_formats\\data\\start_times_part12_seconds.csv\"\n",
    "\n",
    "def timestamp_to_seconds(ts):\n",
    "    \"\"\"\n",
    "    Convert a timestamp 'HH:MM:SS,mmm' to total seconds (float).\n",
    "    \"\"\"\n",
    "    hh, mm, ss_ms = ts.split(':')\n",
    "    ss, ms = ss_ms.split(',')\n",
    "    return int(hh) * 3600 + int(mm) * 60 + int(ss) + int(ms) / 1000.0\n",
    "\n",
    "with open(output_csv, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['recording', 'start_time_p1_seconds', 'start_time_p2_seconds'])\n",
    "\n",
    "    # include both *_P1.txt and *_P2.txt files\n",
    "    for fname in os.listdir(parts_dir):\n",
    "        if not fname.endswith(('_P1.txt', '_P2.txt')):\n",
    "            continue\n",
    "\n",
    "        recording_name = fname.rsplit('.txt', 1)[0]\n",
    "        full_path = os.path.join(parts_dir, fname)\n",
    "\n",
    "        p1_ts = None\n",
    "        p2_ts = None\n",
    "\n",
    "        with open(full_path, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                if p1_ts is None:\n",
    "                    m1 = re.match(r'^\\s*([\\d]{2}:[\\d]{2}:[\\d]{2},\\d{3})\\s+\"1\"', line)\n",
    "                    if m1:\n",
    "                        p1_ts = m1.group(1)\n",
    "                if p2_ts is None:\n",
    "                    m2 = re.match(r'^\\s*([\\d]{2}:[\\d]{2}:[\\d]{2},\\d{3})\\s+\"2\"', line)\n",
    "                    if m2:\n",
    "                        p2_ts = m2.group(1)\n",
    "                if p1_ts and p2_ts:\n",
    "                    break\n",
    "\n",
    "        # convert to seconds, use NaN if missing\n",
    "        secs1 = timestamp_to_seconds(p1_ts) if p1_ts else math.nan\n",
    "        secs2 = timestamp_to_seconds(p2_ts) if p2_ts else math.nan\n",
    "\n",
    "        writer.writerow([recording_name, secs1, secs2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Tempo Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Directory containing the original CSV files\n",
    "cycles_dir = r\"D:\\pyspace\\Djembe\\2025\\mocap_formats\\data\\virtual_cycles\"\n",
    "save_dir= r\"D:\\pyspace\\Djembe\\2025\\mocap_formats\\data\"\n",
    "\n",
    "# Directory where the new CSVs (with cycle_onset, IOI, and tempo columns) will be saved\n",
    "output_dir = os.path.join(save_dir, \"tempo\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(cycles_dir):\n",
    "    if not filename.lower().endswith(\".csv\"):\n",
    "        continue\n",
    "\n",
    "    input_path = os.path.join(cycles_dir, filename)\n",
    "    df = pd.read_csv(input_path)\n",
    "\n",
    "    # Ensure \"Virtual Onset\" column exists\n",
    "    if \"Virtual Onset\" not in df.columns:\n",
    "        print(f\"Skipping {filename}: no 'Virtual Onset' column.\")\n",
    "        continue\n",
    "\n",
    "    # Create a new dataframe with the required columns\n",
    "    df_new = pd.DataFrame()\n",
    "    df_new[\"cycle_onset\"] = df[\"Virtual Onset\"]\n",
    "\n",
    "    # Compute IOI (cycle duration) = time from this onset to the next onset\n",
    "    df_new[\"ioi\"] = df_new[\"cycle_onset\"].shift(-1) - df_new[\"cycle_onset\"]\n",
    "\n",
    "    # Compute tempo in BPM for each cycle: BPM = 4 beats * (60 seconds / cycle duration) = 240 / IOI\n",
    "    df_new[\"tempo\"] = 240.0 / df_new[\"ioi\"]\n",
    "\n",
    "    # Optional: if you prefer to fill the last row’s tempo with the previous value instead of NaN:\n",
    "    # df[\"tempo\"].fillna(method=\"ffill\", inplace=True)\n",
    "\n",
    "    # Save to the new directory, preserving the original filename\n",
    "    output_path = os.path.join(output_dir, filename)\n",
    "    df_new.to_csv(output_path, index=False)\n",
    "\n",
    "    print(f\"Processed {filename} → saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "today = datetime.now().strftime(\"%d%b\").lower()\n",
    "\n",
    "with open('data/selected_piece_list.pkl', 'rb') as f:\n",
    "    piece_list = pickle.load(f)\n",
    "\n",
    "m_idx = 1\n",
    "mode = [\"group\", \"individual\", \"audience\"]\n",
    "dance_mode = mode[m_idx]\n",
    "\n",
    "cluster_data = {\n",
    "    \"file_name\": [],    # string\n",
    "    \n",
    "    \"dmode_name\": [],   # string\n",
    "    \"dmode_seg_idx\": [], # int\n",
    "    \"dmode_start\": [],  # float\n",
    "    \"dmode_end\": [],    # float\n",
    "    \n",
    "    \"cycle_idx\": [],    # int\n",
    "    \"cycle_start\": [],  # float\n",
    "    \"cycle_end\": [],    # float\n",
    "    \n",
    "    \"location\": [],     # string\n",
    "    \"ensemble\": [],     # string\n",
    "    \"day\": [],          # string\n",
    "    \"rec_no\": [], # string\n",
    "    \"piece\": [],        # string\n",
    "    \n",
    "    \"L_traj\": [],      # numpy array\n",
    "    \"R_traj\": [],       # numpy array\n",
    "    \"LR_traj\": [],       # numpy array\n",
    "    \"pelvis_traj\": [],\n",
    "    \n",
    "    \"L_onsets\": [],\n",
    "    \"R_onsets\": [],\n",
    "    \n",
    "    \"Dun\": [],\n",
    "    \"J1\": [],\n",
    "    \"J2\": [],\n",
    "}\n",
    "\n",
    "# left and right foot onsets by cycle per mode\n",
    "# three drum onsets by cycle per mode\n",
    "\n",
    "\n",
    "\n",
    "motion_data_dir = \"data/motion_data_pkl\"\n",
    "\n",
    "for file_name in piece_list:\n",
    "    \n",
    "    # print(file_name)\n",
    "    # file_name = piece_list[0]  # BKO_E1_D1_01_Suku\n",
    "    location = file_name.split(\"_\")[0]      # BKO\n",
    "    ensemble = file_name.split(\"_\")[1]      # E1\n",
    "    day = file_name.split(\"_\")[2]           # D1\n",
    "    recording_no = file_name.split(\"_\")[3]  # 01\n",
    "    piece = file_name.split(\"_\")[4]         # Suku\n",
    "\n",
    "\n",
    "    base_path_cycles = \"data/virtual_cycles\"\n",
    "    onsets_csv_path = f\"data/drum_onsets/{file_name}.csv\"\n",
    "    base_path_logs= \"data/logs_v4_0.007_foot_jun3\"           # \"data/logs_v2_may\",   # \"data/logs_v3_0.2_lower_jun3\",    # \"data/logs_v4_0.007_foot_jun3\", \n",
    "    dance_mode_path = f\"data/dance_modes_ts/{file_name}_{dance_mode}.pkl\"\n",
    "    drum_onsets_path = f\"data/drum_onsets/{file_name}.csv\"\n",
    "\n",
    "    # build file paths\n",
    "    cycles_csv = os.path.join(base_path_cycles, f\"{file_name}_C.csv\")\n",
    "    logs_onset_dir = os.path.join(base_path_logs, f\"{file_name}_T\", \"onset_info\")\n",
    "\n",
    "    left_onsets_csv  = os.path.join(logs_onset_dir, f\"{file_name}_T_left_foot_onsets.csv\")\n",
    "    right_onsets_csv = os.path.join(logs_onset_dir, f\"{file_name}_T_right_foot_onsets.csv\")\n",
    "    left_zpos_csv    = os.path.join(logs_onset_dir, f\"{file_name}_T_left_foot_zpos.csv\")\n",
    "    right_zpos_csv   = os.path.join(logs_onset_dir, f\"{file_name}_T_right_foot_zpos.csv\")\n",
    "    \n",
    "    # Load the mocap pickle file\n",
    "    mpkl_path = f\"{motion_data_dir}/{file_name}_T.pkl\"\n",
    "    with open(mpkl_path, 'rb') as f:\n",
    "        motion_data = pickle.load(f)\n",
    "\n",
    "    # pelvis position data\n",
    "    pelvis_zpos = motion_data[\"position\"]['SEGMENT_PELVIS'][:,2]        # mocap 240 fps\n",
    "    pelvis_n_frames = len(pelvis_zpos)\n",
    "    pelvis_times = np.arange(pelvis_n_frames) / 240\n",
    "    \n",
    "    # Load feet onset data\n",
    "    L_onsets = pd.read_csv(left_onsets_csv)[\"time_sec\"].values\n",
    "    R_onsets = pd.read_csv(right_onsets_csv)[\"time_sec\"].values\n",
    "    \n",
    "    Dun_onsets = pd.read_csv(drum_onsets_path)[\"Dun\"].values\n",
    "    J1_onsets = pd.read_csv(drum_onsets_path)[\"J1\"].values\n",
    "    J2_onsets = pd.read_csv(drum_onsets_path)[\"J2\"].values\n",
    "\n",
    "    \n",
    "    # load feet position data\n",
    "    Left_zpos = pd.read_csv(left_zpos_csv)[\"zpos\"].values\n",
    "    Right_zpos = pd.read_csv(right_zpos_csv)[\"zpos\"].values\n",
    "    n_frames = len(Left_zpos)\n",
    "    times = np.arange(n_frames) / 240\n",
    "\n",
    "    # load cycles\n",
    "    cyc_df = pd.read_csv(cycles_csv)\n",
    "\n",
    "    # load dance mode time segments\n",
    "    if os.path.exists(dance_mode_path):\n",
    "        with open(dance_mode_path, \"rb\") as f:\n",
    "            dmode_ts = pickle.load(f)\n",
    "    else:\n",
    "        print(f\"{file_name} {dance_mode} does not exist\")\n",
    "        continue\n",
    "    # print(location, ensemble, day, recording_no, piece)\n",
    "    # print(dance_mode)\n",
    "    # print(dmode_ts) \n",
    "    \n",
    "    \n",
    "    for dmode_idx, dmode in enumerate(dmode_ts):\n",
    "        dmode_start, dmode_end = dmode\n",
    "        # print(\"dmode_seg_no:\", dmode_idx+1)\n",
    "        # print(\"dmode_segment:\", dmode_start, dmode_end)\n",
    "\n",
    "        onsets = cyc_df[\"Virtual Onset\"].values     # in seconds\n",
    "\n",
    "        # Filter onsets to get only those within the dance mode time segment\n",
    "        mode_mask = (onsets >= dmode_start) & (onsets <= dmode_end)\n",
    "        mode_onsets = onsets[mode_mask]\n",
    "\n",
    "        # Create list of tuples with start and end times of cycles within the dance mode segment\n",
    "        cycle_times = [(round(mode_onsets[i], 3), round(mode_onsets[i+1], 3)) for i in range(len(mode_onsets)-1)]\n",
    "        # print(\"cycle_times:\", cycle_times)\n",
    "\n",
    "        for c_idx, (c_start, c_end) in enumerate(cycle_times):\n",
    "            # print(\"cycle:\", c_idx+1, c_start, c_end)\n",
    "        \n",
    "            win_mask = (times >= c_start) & (times <= c_end)\n",
    "            t_win = times[win_mask]\n",
    "            \n",
    "            # feet\n",
    "            Left_zpos_win = Left_zpos[win_mask]\n",
    "            Right_zpos_win = Right_zpos[win_mask]\n",
    "            left_right_zpos = np.concatenate((Left_zpos_win, Right_zpos_win))\n",
    "            \n",
    "            # pelvis\n",
    "            pelvis_win_mask = (pelvis_times >= c_start) & (pelvis_times <= c_end)\n",
    "            pelvis_t_win = pelvis_times[pelvis_win_mask]\n",
    "            pelvis_zpos_win = pelvis_zpos[pelvis_win_mask]\n",
    "            \n",
    "            # feet onsets\n",
    "            c_left_onset = L_onsets[(L_onsets >= c_start) & (L_onsets <= c_end)]\n",
    "            c_right_onset = R_onsets[(R_onsets >= c_start) & (R_onsets <= c_end)]\n",
    "            # drum onsets\n",
    "            c_Dun_onset = Dun_onsets[(Dun_onsets >= c_start) & (Dun_onsets <= c_end)]\n",
    "            c_J1_onset = J1_onsets[(J1_onsets >= c_start) & (J1_onsets <= c_end)]\n",
    "            c_J2_onset = J2_onsets[(J2_onsets >= c_start) & (J2_onsets <= c_end)]\n",
    "            \n",
    "            # save \n",
    "            cluster_data[\"file_name\"].append(file_name)\n",
    "            \n",
    "            cluster_data[\"dmode_name\"].append(dance_mode)\n",
    "            cluster_data[\"dmode_seg_idx\"].append(dmode_idx+1)\n",
    "            cluster_data[\"dmode_start\"].append(dmode_start)\n",
    "            cluster_data[\"dmode_end\"].append(dmode_end)\n",
    "            \n",
    "            cluster_data[\"cycle_idx\"].append(c_idx+1)\n",
    "            cluster_data[\"cycle_start\"].append(c_start)\n",
    "            cluster_data[\"cycle_end\"].append(c_end)\n",
    "\n",
    "            cluster_data[\"location\"].append(location)\n",
    "            cluster_data[\"ensemble\"].append(ensemble)\n",
    "            cluster_data[\"day\"].append(day)\n",
    "            cluster_data[\"rec_no\"].append(recording_no)\n",
    "            cluster_data[\"piece\"].append(piece)\n",
    "            \n",
    "            cluster_data[\"L_traj\"].append(Left_zpos_win)\n",
    "            cluster_data[\"R_traj\"].append(Right_zpos_win)\n",
    "            cluster_data[\"LR_traj\"].append(left_right_zpos)\n",
    "            cluster_data[\"pelvis_traj\"].append(pelvis_zpos_win)\n",
    "            \n",
    "            cluster_data[\"L_onsets\"].append(c_left_onset)\n",
    "            cluster_data[\"R_onsets\"].append(c_right_onset)\n",
    "            \n",
    "            cluster_data[\"Dun\"].append(c_Dun_onset)\n",
    "            cluster_data[\"J1\"].append(c_J1_onset)\n",
    "            cluster_data[\"J2\"].append(c_J2_onset)\n",
    "            \n",
    "        \n",
    "            # plt.plot(pelvis_t_win, pelvis_zpos_win, label='Left Foot')\n",
    "            # plt.legend()\n",
    "            # plt.show()\n",
    "\n",
    "with open(f\"cluster_data_{dance_mode}_{today}.pkl\", \"wb\") as f:\n",
    "    pickle.dump(cluster_data, f)\n",
    "\n",
    "from scipy.io import savemat\n",
    "savemat(f\"cluster_data_{dance_mode}_with_pelvis_{today}.mat\", cluster_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plot\n",
    "plt.plot(t_win, Left_zpos_win, label='Left Foot')\n",
    "plt.plot(t_win, Right_zpos_win, label='Right Foot')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
