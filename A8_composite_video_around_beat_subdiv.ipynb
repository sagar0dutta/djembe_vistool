{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import subprocess\n",
    "# import pandas as pd\n",
    "from utils_mocap_viz.generate_views import (    # organize this\n",
    "    # get_output_dir,\n",
    "    prepare_videos\n",
    ")\n",
    "\n",
    "from utils_mocap_viz.animated_merged_phase_analysis import animate_merged_phase_analysis\n",
    "from utils_dance_anim.dance_dot import animate_dance_phase_analysis\n",
    "\n",
    "\n",
    "from utils_pipeline.pipeline_B import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded cycle_segments from BKO_E1_D1_02_Maraka_included_0.001.pkl\n",
      "cycle_segments: [(23.740333333, 26.174999999666667), (26.174999999666667, 28.663888888666666), (28.663888888666666, 31.07633333333333), (31.07633333333333, 33.48166666633333), (33.48166666633333, 35.851444444), (35.851444444, 38.19277777766667), (38.19277777766667, 40.538555555), (40.538555555, 42.90566666666667), (42.90566666666667, 45.23455555533334), (45.23455555533334, 47.571), (47.571, 49.90033333333333), (49.90033333333333, 52.17588888866667), (52.17588888866667, 54.4496666665), (54.4496666665, 56.688777777666665), (56.688777777666665, 58.955), (58.955, 61.175), (61.175, 63.60966666666667)]\n",
      "Number of windows for each beat/subdivision:\n",
      "  beat_1: 17 windows\n",
      "  beat_2: 17 windows\n",
      "  beat_3: 17 windows\n",
      "  beat_4: 17 windows\n",
      "  subdiv_2: 17 windows\n",
      "  subdiv_3: 17 windows\n",
      "  subdiv_5: 17 windows\n",
      "  subdiv_6: 17 windows\n",
      "  subdiv_8: 17 windows\n",
      "  subdiv_9: 17 windows\n",
      "  subdiv_11: 17 windows\n",
      "  subdiv_12: 17 windows\n"
     ]
    }
   ],
   "source": [
    "file_name = \"BKO_E1_D1_02_Maraka\"\n",
    "traj_dir  = \"traj_files_presentation\"\n",
    "status    = \"included\"   # or \"excluded\"\n",
    "traj_threshold = \"0.001\"        # or any other threshold\n",
    "\n",
    "bvh_dir = os.path.join(\"data\", \"bvh_files\")\n",
    "bvh_file = os.path.join(bvh_dir, file_name + \"_T\")\n",
    "\n",
    "# path to onsets and cycles csv files\n",
    "cycles_csv_path = f\"data/virtual_cycles/{file_name}_C.csv\"\n",
    "onsets_csv_path = f\"data/drum_onsets/{file_name}.csv\"\n",
    "dance_csv_path = f\"data/dance_onsets/{file_name}_T_dance_onsets.csv\"\n",
    "\n",
    "cycle_segs, windows = compute_windows(traj_dir, file_name, status, traj_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate trajectory video + trimmed dance video plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(21.30566666633333, 26.174999999666667, 23.740333333),\n",
       " (23.68611111066667, 28.663888888666666, 26.174999999666667)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'beat_1', 'beat_2', 'beat_3', 'beat_4', \n",
    "# 'subdiv_2', 'subdiv_3', 'subdiv_5', 'subdiv_6', \n",
    "# 'subdiv_8', 'subdiv_9', 'subdiv_11', 'subdiv_12'\n",
    "\n",
    "w_key = \"beat_1\"\n",
    "vid_plot_path = f\"cycle_videos/{file_name}/{w_key}/\"\n",
    "\n",
    "traj_tuples = windows[w_key][:2]\n",
    "# traj_tuples = random.sample(windows[w_key], 2)  # Randomly sample 2 tuples from the list\n",
    "\n",
    "traj_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Windows data:\n",
      "Window 1:\n",
      "  Start: 21.306\n",
      "  End: 26.175\n",
      "  Duration: 4.869\n",
      "Window 2:\n",
      "  Start: 23.686\n",
      "  End: 28.664\n",
      "  Duration: 4.978\n",
      "\n",
      "Foot data ranges:\n",
      "Left foot time range: 0.733 to 340.450\n",
      "Right foot time range: 0.267 to 339.721\n",
      "Number of left foot onsets: 240\n",
      "Number of right foot onsets: 234\n",
      "\n",
      "Processing 2 windows\n",
      "Total frames in trajectory data: 81793\n",
      "Time range in trajectory data: 0.000 to 340.800\n",
      "\n",
      "Processing window 1:\n",
      "  Window time range: 21.306 to 26.175\n",
      "  Found 3 left foot onsets and 3 right foot onsets\n",
      "  Left foot onset times: [21.8875     22.47916667 24.95416667]\n",
      "  Right foot onset times: [21.325      23.72916667 26.17083333]\n",
      "  Video frames: 1065 to 1308 (50fps)\n",
      "  Trajectory frames: 5113 to 6281 (240fps)\n",
      "  Trajectory data points: 1168\n",
      "\n",
      "Video extraction:\n",
      "Input video: data/videos/BKO_E1_D1_02_Maraka_pre_R_Mix.mp4\n",
      "Output video: composite_videos\\BKO_E1_D1_02_Maraka\\beat_1\\videos\\BKO_E1_D1_02_Maraka_window_001_21.31_26.17.mp4\n",
      "Start time: 21.30566666633333\n",
      "Duration: 4.869333333333337\n",
      "FFmpeg command: ffmpeg -y -i data/videos/BKO_E1_D1_02_Maraka_pre_R_Mix.mp4 -ss 21.30566666633333 -t 4.869333333333337 -c:v libx264 -c:a aac -r 24 composite_videos\\BKO_E1_D1_02_Maraka\\beat_1\\videos\\BKO_E1_D1_02_Maraka_window_001_21.31_26.17.mp4\n",
      "Video extraction successful\n",
      "Output file exists: composite_videos\\BKO_E1_D1_02_Maraka\\beat_1\\videos\\BKO_E1_D1_02_Maraka_window_001_21.31_26.17.mp4\n",
      "File size: 2621556 bytes\n",
      "  Video saved: composite_videos\\BKO_E1_D1_02_Maraka\\beat_1\\videos\\BKO_E1_D1_02_Maraka_window_001_21.31_26.17.mp4\n",
      "  Plot saved: composite_videos\\BKO_E1_D1_02_Maraka\\beat_1\\plots\\BKO_E1_D1_02_Maraka_window_001_21.31_26.17.mp4\n",
      "  Video duration: 4.869s\n",
      "  Plot duration: 4.833s\n",
      "\n",
      "Processing window 2:\n",
      "  Window time range: 23.686 to 28.664\n",
      "  Found 2 left foot onsets and 2 right foot onsets\n",
      "  Left foot onset times: [24.95416667 27.42083333]\n",
      "  Right foot onset times: [23.72916667 26.17083333]\n",
      "  Video frames: 1184 to 1433 (50fps)\n",
      "  Trajectory frames: 5684 to 6879 (240fps)\n",
      "  Trajectory data points: 1195\n",
      "\n",
      "Video extraction:\n",
      "Input video: data/videos/BKO_E1_D1_02_Maraka_pre_R_Mix.mp4\n",
      "Output video: composite_videos\\BKO_E1_D1_02_Maraka\\beat_1\\videos\\BKO_E1_D1_02_Maraka_window_002_23.69_28.66.mp4\n",
      "Start time: 23.68611111066667\n",
      "Duration: 4.9777777779999965\n",
      "FFmpeg command: ffmpeg -y -i data/videos/BKO_E1_D1_02_Maraka_pre_R_Mix.mp4 -ss 23.68611111066667 -t 4.9777777779999965 -c:v libx264 -c:a aac -r 24 composite_videos\\BKO_E1_D1_02_Maraka\\beat_1\\videos\\BKO_E1_D1_02_Maraka_window_002_23.69_28.66.mp4\n",
      "Video extraction successful\n",
      "Output file exists: composite_videos\\BKO_E1_D1_02_Maraka\\beat_1\\videos\\BKO_E1_D1_02_Maraka_window_002_23.69_28.66.mp4\n",
      "File size: 2851957 bytes\n",
      "  Video saved: composite_videos\\BKO_E1_D1_02_Maraka\\beat_1\\videos\\BKO_E1_D1_02_Maraka_window_002_23.69_28.66.mp4\n",
      "  Plot saved: composite_videos\\BKO_E1_D1_02_Maraka\\beat_1\\plots\\BKO_E1_D1_02_Maraka_window_002_23.69_28.66.mp4\n",
      "  Video duration: 4.978s\n",
      "  Plot duration: 4.958s\n",
      "\n",
      "Processing complete!\n"
     ]
    }
   ],
   "source": [
    "# to plot window around a beat, with 1 cycles before and after the beat,\n",
    "# beat is placed at zero, and cycles are plotted around it.\n",
    "# x axis ranges from -4 to 4, representing beat numbers\n",
    "\n",
    "extract_centered_cycle_videos_and_plots(\n",
    "    file_name = file_name,\n",
    "    windows = traj_tuples,  # List of (win_start, win_end, t_poi) tuples\n",
    "    window_key = w_key,\n",
    "    base_path_logs = \"data/logs_v4_0.007_foot_jun3\",            # logs_v4_0.007_foot_jun3       logs_v2_may\n",
    "    figsize = (10, 3),\n",
    "    dpi = 200,\n",
    "    save_dir = \"composite_videos\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Skeletal video + trimmed_video_mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = os.path.join(\"data\", \"videos\", f\"{file_name}_pre_R_Mix.mp4\")\n",
    "\n",
    "output_dir1 = os.path.join(\"composite_videos\", file_name, w_key, \"video_skeleton\")\n",
    "os.makedirs(output_dir1, exist_ok=True)\n",
    "\n",
    "output_dir3 = os.path.join(\"composite_videos\", file_name, w_key, \"drum_dot_merged\")\n",
    "os.makedirs(output_dir3, exist_ok=True)\n",
    "\n",
    "output_dir4 = os.path.join(\"composite_videos\", file_name, w_key, \"dance_dot\")\n",
    "os.makedirs(output_dir4, exist_ok=True)\n",
    "\n",
    "for start_time, end_time, _ in traj_tuples:\n",
    "\n",
    "    save_fname = f\"drum_dot_merged_{start_time:.2f}_{end_time:.2f}.mp4\"\n",
    "    animate_merged_phase_analysis(\n",
    "        file_name, start_time, end_time,\n",
    "        cycles_csv_path, onsets_csv_path,\n",
    "        figsize=(10, 3), dpi=200,\n",
    "        save_fname = save_fname,\n",
    "        save_dir=output_dir3\n",
    "        )\n",
    "    \n",
    "    animate_dance_phase_analysis(\n",
    "        file_name, start_time, end_time,\n",
    "        cycles_csv_path, dance_csv_path,\n",
    "        figsize= (10, 3), dpi= 200, save_dir= output_dir4\n",
    "    )\n",
    "\n",
    "    view_videos = prepare_videos(\n",
    "        filename= bvh_file,\n",
    "        start_time= start_time,\n",
    "        end_time= end_time,\n",
    "        views_to_generate = ['front'],\n",
    "        video_path= None,             # video_path, wonr generate video\n",
    "        video_size= (1280, 720),\n",
    "        fps= 24,\n",
    "        output_dir = output_dir1\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate animated kinematic plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate animated kinematic plots: x axis in seconds\n",
    "# joint_name = \"Hips\"  \n",
    "# axis = 'y'      # y is vertical in bvh files\n",
    "\n",
    "# output_dir2 = os.path.join(\"composite_videos\", file_name, w_key, joint_name)\n",
    "# os.makedirs(output_dir2, exist_ok=True)\n",
    "\n",
    "\n",
    "# for start_time, end_time, _ in traj_tuples:\n",
    "#     print(start_time, end_time)\n",
    "\n",
    "#     visualize_joint_position(\n",
    "#         bvh_file=bvh_file + \".bvh\",\n",
    "#         joint_name= joint_name,\n",
    "#         axis= axis,\n",
    "#         start_time= start_time,\n",
    "#         end_time= end_time,\n",
    "#         output_fps= 24,\n",
    "#         output_dir= output_dir2,\n",
    "#         fig_size= (12, 4),  # Half height for joint visualization\n",
    "#         dpi= 200\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cycle_plots(\n",
    "    file_name: str,\n",
    "    windows: list,  # List of (win_start, win_end, t_poi) tuples\n",
    "    window_key: str,\n",
    "    joint_name: str,\n",
    "    axis: str = 'y',\n",
    "    base_path_logs: str = \"data/logs_v2_may\",\n",
    "    frame_rate: float = 240,  # Trajectory data frame rate\n",
    "    n_beats_per_cycle: int = 4,\n",
    "    n_subdiv_per_beat: int = 3,\n",
    "    nn: int = 3,\n",
    "    output_dir2: str = None,\n",
    "    figsize: tuple = (10, 3),\n",
    "    dpi: int = 200\n",
    "):\n",
    "    \"\"\"\n",
    "    Create trajectory animations for windows around points of interest (beats or subdivisions).\n",
    "    Each plot shows [-cycle, 0-cycle, +cycle] around the POI.\n",
    "    \"\"\"\n",
    "    # Create save directory if not provided\n",
    "    if output_dir2 is None:\n",
    "        \n",
    "        output_dir2 = os.path.join(\"cycle_plots\", file_name, window_key, joint_name)\n",
    "    os.makedirs(output_dir2, exist_ok=True)\n",
    "    \n",
    "    # Load joint position data\n",
    "    dir_csv = \"extracted_mocap_csv\"\n",
    "    base_name = os.path.splitext(os.path.basename(file_name))[0]\n",
    "    worldpos_file = os.path.join(dir_csv, f\"{base_name}_T_worldpos.csv\")\n",
    "    \n",
    "    try:\n",
    "        world_positions = pd.read_csv(worldpos_file)\n",
    "        print(f\"Successfully loaded CSV with {len(world_positions)} rows\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading CSV file: {e}\")\n",
    "        raise\n",
    "    \n",
    "    # Get time column and position data\n",
    "    time_column = world_positions.columns[0]  # First column is time\n",
    "    times = world_positions[time_column].values\n",
    "    positions = world_positions[f\"{joint_name}.{axis.upper()}\"].values\n",
    "    \n",
    "    print(f\"\\nProcessing {len(windows)} windows\")\n",
    "    # print(f\"Total frames in trajectory data: {len(times)}\")\n",
    "    # print(f\"Time range in trajectory data: {times[0]:.3f} to {times[-1]:.3f}\")\n",
    "    \n",
    "    # Process each window\n",
    "    for i, (win_start, win_end, t_poi) in enumerate(windows):\n",
    "        print(f\"\\nProcessing window {i+1}:\")\n",
    "        print(f\"  Window time range: {win_start:.3f} to {win_end:.3f}\")\n",
    "        \n",
    "        # Calculate segment times\n",
    "        start_time = win_start\n",
    "        end_time = win_end\n",
    "        duration = end_time - start_time\n",
    "        downbeat = t_poi  # This is the point of interest (beat or subdivision)\n",
    "        \n",
    "        # Calculate avg_cycle from the window duration\n",
    "        avg_cycle = duration / 2  # Since window is ±1 cycle\n",
    "        \n",
    "        # Calculate window parameters\n",
    "        beat_len = avg_cycle / n_beats_per_cycle\n",
    "        subdiv_len = beat_len / n_subdiv_per_beat\n",
    "        half_win = subdiv_len * nn\n",
    "        \n",
    "        # Calculate frame numbers for trajectory (240fps)\n",
    "        traj_start_frame = int(start_time * frame_rate)\n",
    "        traj_end_frame = int(end_time * frame_rate)\n",
    "        traj_n_frames = traj_end_frame - traj_start_frame\n",
    "        \n",
    "        print(f\"  Trajectory frames: {traj_start_frame} to {traj_end_frame} (240fps)\")\n",
    "        \n",
    "        # Check if we have valid frame numbers\n",
    "        if traj_start_frame >= traj_end_frame:\n",
    "            print(f\"  Skipping window {i+1}: Invalid frame range (start >= end)\")\n",
    "            continue\n",
    "        if traj_start_frame < 0:\n",
    "            print(f\"  Skipping window {i+1}: Start frame < 0\")\n",
    "            continue\n",
    "        if traj_end_frame > len(positions):\n",
    "            print(f\"  Skipping window {i+1}: End frame > total frames\")\n",
    "            continue\n",
    "        \n",
    "        # Trim trajectory data using frame numbers at 240fps\n",
    "        pos_win = positions[traj_start_frame:traj_end_frame]\n",
    "        t_win = times[traj_start_frame:traj_end_frame]\n",
    "        \n",
    "        # Check if we have valid trajectory data\n",
    "        if len(pos_win) == 0:\n",
    "            print(f\"  Skipping window {i+1}: No trajectory data\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"  Trajectory data points: {len(pos_win)}\")\n",
    "        \n",
    "        # Create figure and axis\n",
    "        fig, ax = plt.subplots(figsize=figsize, dpi=dpi)\n",
    "        fig.tight_layout(pad=2.0) \n",
    "        \n",
    "        # Calculate all subdivision times for the window\n",
    "        all_subdiv_times = []\n",
    "        for beat_idx in range(-n_beats_per_cycle, n_beats_per_cycle + 1):\n",
    "            beat_time = downbeat + beat_idx * beat_len\n",
    "            for subdiv_idx in range(n_subdiv_per_beat):\n",
    "                subdiv_time = beat_time + subdiv_idx * subdiv_len\n",
    "                if start_time <= subdiv_time <= end_time:\n",
    "                    all_subdiv_times.append((subdiv_time, beat_idx * n_subdiv_per_beat + subdiv_idx + 1))\n",
    "\n",
    "        # Plot subdivision lines with appropriate colors\n",
    "        for subdiv_time, subdiv_num in all_subdiv_times:\n",
    "            color = get_subdiv_color(subdiv_num)\n",
    "            # Add yellow glow effect for t=0\n",
    "            if abs(subdiv_time - downbeat) < 0.001:  # If it's the POI\n",
    "                ax.axvline(subdiv_time, color='yellow', linestyle='-', linewidth=3, alpha=0.3)\n",
    "            # ax.axvline(subdiv_time, color=color, linestyle='-', linewidth=2, alpha=0.7)\n",
    "            \n",
    "            if subdiv_num in [-11, -8, -5, -2, 1, 4, 7, 10]:\n",
    "                ax.axvline(subdiv_time, color=color, linestyle='-', linewidth=2, alpha=0.7) #beat color\n",
    "            else:\n",
    "                ax.axvline(subdiv_time, color=color, linestyle='--', linewidth=1, alpha=0.3) #subdivision color\n",
    "        \n",
    "        # Plot trajectory\n",
    "        ax.plot(t_win, pos_win, '-', color='green', alpha=0.5, label=f'{joint_name} {axis.upper()}')\n",
    "        \n",
    "        ax.axvline(downbeat, color='yellow', linewidth=6, alpha=0.3, zorder=0)  # Glow effect\n",
    "        \n",
    "        # Set y-axis limits with safety checks\n",
    "        try:\n",
    "            y_min = pos_win.min()\n",
    "            y_max = pos_win.max()\n",
    "            y_range = y_max - y_min\n",
    "            ax.set_ylim(y_min - 0.1*y_range, y_max + 0.1*y_range)\n",
    "        except ValueError as e:\n",
    "            print(f\"  Warning: Could not set y-axis limits: {e}\")\n",
    "            # Set default y-axis limits\n",
    "            ax.set_ylim(-1, 1)\n",
    "        \n",
    "        # Create vertical playhead\n",
    "        v_playhead, = ax.plot([start_time, start_time], \n",
    "                            [y_min - 0.1*y_range, y_max + 0.1*y_range],\n",
    "                            lw=1, alpha=0.9, color='orange')\n",
    "        \n",
    "        # Set up the plot with scaled x-axis\n",
    "        ax.set_xlabel(f'Beats relative to {window_key}')\n",
    "        ax.set_ylabel(f'{joint_name} Z Position')      # {axis.upper()} y is vertical in bvh files, Z is vertical in mocap\n",
    "        ax.set_title(f'Window {i+1} | {window_key}: {downbeat:.2f}s')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Scale x-axis to show beats instead of cycles\n",
    "        x_ticks = np.arange(-n_beats_per_cycle, n_beats_per_cycle + 1)\n",
    "        x_tick_positions = downbeat + x_ticks * beat_len\n",
    "        ax.set_xticks(x_tick_positions)\n",
    "        ax.set_xticklabels(x_ticks)\n",
    "        \n",
    "        # Add legend\n",
    "        custom = [\n",
    "            Line2D([0],[0], color='blue', lw=1),\n",
    "            Line2D([0],[0], color='black', lw=1),\n",
    "            Line2D([0],[0], color='green', lw=1),\n",
    "            Line2D([0],[0], color='red', lw=1),\n",
    "        ]\n",
    "        labels = [\n",
    "            f\"{joint_name} {axis.upper()}\", \n",
    "            \"Subdiv-1 (1,4,7,10)\", \n",
    "            \"Subdiv-2 (2,5,8,11)\", \n",
    "            \"Subdiv-3 (3,6,9,12)\"\n",
    "        ]\n",
    "        ax.legend(custom, labels, loc='upper left', framealpha=0.3, fontsize=6)\n",
    "        \n",
    "        def update(frame):\n",
    "            v_playhead.set_xdata([frame, frame])\n",
    "            ax.set_title(f'Cycle {i+1} | {window_key}: {downbeat:.2f}s | Time: {frame:.2f}s')\n",
    "            return v_playhead,\n",
    "        \n",
    "        # Create animation frames at 24fps\n",
    "        n_frames = int(duration * 24)\n",
    "        frames = np.linspace(start_time, end_time, n_frames)\n",
    "        anim = animation.FuncAnimation(\n",
    "            fig, update, frames=frames,\n",
    "            interval=1000/24,  # 24fps\n",
    "            blit=True\n",
    "        )\n",
    "        \n",
    "        # Save animation\n",
    "        plot_output_path = os.path.join(output_dir2, f\"{file_name}_window_{i+1:03d}_{start_time:.2f}_{end_time:.2f}.mp4\")\n",
    "        writer = animation.FFMpegWriter(fps= 24, \n",
    "                                        bitrate=2000,\n",
    "                                        codec='libx264',  # Specify codec\n",
    "                                        # extra_args=['-preset', 'ultrafast']\n",
    "                                        )  # 24fps\n",
    "        anim.save(plot_output_path, writer=writer)\n",
    "        plt.close(fig)\n",
    "        \n",
    "        print(f\"  Plot saved: {plot_output_path}\")\n",
    "        print(f\"  Plot duration: {len(frames)/24:.3f}s\")\n",
    "    \n",
    "    print(\"\\nProcessing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Available markers: ['Hips', 'LeftHip', 'LeftKnee', 'LeftAnkle', 'LeftToe', \n",
    "# 'LeftToeEnd', 'RightHip', 'RightKnee', 'RightAnkle', 'RightToe', 'RightToeEnd', \n",
    "# 'Chest', 'Chest2', 'Chest3', 'Chest4', 'LeftCollar', 'LeftShoulder', 'LeftElbow', \n",
    "# 'LeftWrist', 'LeftWristEnd', 'RightCollar', 'RightShoulder', 'RightElbow', \n",
    "# 'RightWrist', 'RightWristEnd', 'Neck', 'Head', 'HeadEnd']\n",
    "\n",
    "joint_name = \"Hips\"  \n",
    "axis = 'y'      # y is vertical in bvh files\n",
    "\n",
    "output_dir2 = os.path.join(\"composite_videos\", file_name, w_key, joint_name)\n",
    "os.makedirs(output_dir2, exist_ok=True)\n",
    "\n",
    "extract_cycle_plots(\n",
    "file_name= file_name,\n",
    "windows= traj_tuples,\n",
    "window_key= w_key,\n",
    "joint_name= joint_name,\n",
    "axis=\"y\",\n",
    "output_dir2= output_dir2,\n",
    "figsize = (10, 3),  # 2000 x 600 px\n",
    "dpi= 200,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate merged distribution video plot (DunDun, J1, J2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare for concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_category(filename):\n",
    "    \"\"\"\n",
    "    Given a filename like \"front_view_56.7_61.2.mp4\" or\n",
    "    \"BKO_E1_D1_02_Maraka_pre_R_Mix_trimmed_56.7_61.2.mp4\",\n",
    "    return the category portion before the last two underscore-separated tokens.\n",
    "    \"\"\"\n",
    "    name, _ = os.path.splitext(filename)     # strip .mp4\n",
    "    parts = name.split('_')\n",
    "    # Last two parts are start and end times, so category is everything before them\n",
    "    if len(parts) > 2:\n",
    "        return \"_\".join(parts[:-2])\n",
    "    return name   # fallback if unexpected format\n",
    "\n",
    "def write_all_categories(files, output_dir, video_dir):\n",
    "    \"\"\"\n",
    "    From a list of filenames, group by category (as defined by extract_category),\n",
    "    and write each group into its own .txt file in output_dir.\n",
    "    \"\"\"\n",
    "    # os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Group filenames by category\n",
    "    categories = {}\n",
    "    for fname in files:\n",
    "        cat = extract_category(fname)\n",
    "        categories.setdefault(cat, []).append(fname)\n",
    "\n",
    "    # Write each category's filenames to a separate text file\n",
    "    for cat, fnames in categories.items():\n",
    "        txt_path = os.path.join(output_dir, f\"{cat}.txt\")\n",
    "        with open(txt_path, \"w\") as fw:\n",
    "            for f in fnames:\n",
    "                if video_dir:\n",
    "                    rel_path = os.path.relpath(os.path.join(video_dir, f), os.path.dirname(txt_path))\n",
    "                    fw.write(f\"file '{rel_path}'\\n\")\n",
    "                else:\n",
    "                    fw.write(f + \"\\n\")  \n",
    "                \n",
    "\n",
    "def create_concat_file(video_dir, output_file, prefix):\n",
    "    \"\"\"Create a text file listing all videos in order for concatenation\"\"\"\n",
    "    with open(output_file, 'w') as f:\n",
    "        # Get all video files and sort them\n",
    "        video_files = sorted([f for f in os.listdir(video_dir) if f.endswith('.mp4')])\n",
    "        # Write each file path - use relative path from the text file location\n",
    "        for video in video_files:\n",
    "            # Get relative path from output_file to video_dir\n",
    "            rel_path = os.path.relpath(os.path.join(video_dir, video), os.path.dirname(output_file))\n",
    "            f.write(f\"file '{rel_path}'\\n\") \n",
    "            \n",
    "def concatenate_and_overlay_videos(file_name, joint_name,  save_dir):\n",
    "    \"\"\"Concatenate cycle videos and plot videos, then overlay them\"\"\"\n",
    "    video_dir = os.path.join(save_dir, \"videos\")\n",
    "    plot_dir = os.path.join(save_dir, \"plots\")\n",
    "    joint_dir = os.path.join(save_dir, joint_name)\n",
    "    vid_skel_dir = os.path.join(save_dir, \"video_skeleton\")\n",
    "    drum_dot_dir = os.path.join(save_dir, \"drum_dot_merged\")\n",
    "    dance_dot_dir = os.path.join(save_dir, \"dance_dot\")\n",
    "\n",
    "    # Create text files for concatenation\n",
    "    video_list = os.path.join(save_dir, \"video_list.txt\")\n",
    "    plot_list = os.path.join(save_dir, \"plot_list.txt\")\n",
    "    joint_list = os.path.join(save_dir, \"joint_list.txt\")\n",
    "    \n",
    "    drum_dot_list = os.path.join(save_dir, \"drum_dot_list.txt\")\n",
    "    dance_dot_list = os.path.join(save_dir, \"dance_dot_list.txt\")\n",
    "    \n",
    "    front_view_list = os.path.join(save_dir, \"front_view.txt\")\n",
    "    # left_view_list = os.path.join(save_dir, \"left_view.txt\")\n",
    "    # right_view_list = os.path.join(save_dir, \"right_view.txt\")\n",
    "    # top_view_list = os.path.join(save_dir, \"top_view.txt\")\n",
    "    \n",
    "    \n",
    "    mp4_file_list = [f for f in os.listdir(vid_skel_dir) if f.lower().endswith(\".mp4\")]\n",
    "    write_all_categories(mp4_file_list, save_dir, video_dir = vid_skel_dir)\n",
    "    \n",
    "    \n",
    "    # Check if directories exist\n",
    "    if not os.path.exists(video_dir):\n",
    "        print(f\"Video directory not found: {video_dir}\")\n",
    "        return\n",
    "    if not os.path.exists(plot_dir):\n",
    "        print(f\"Plot directory not found: {plot_dir}\")\n",
    "        return\n",
    "        \n",
    "    # Check if text files already exist\n",
    "    if os.path.exists(video_list) and os.path.exists(plot_list):\n",
    "        print(\"Concatenation files already exist, skipping creation\")\n",
    "    else:\n",
    "        print(\"Creating concatenation files...\")\n",
    "        create_concat_file(video_dir, video_list, f\"{file_name}_cycle_\")\n",
    "        create_concat_file(plot_dir, plot_list, f\"{file_name}_cycle_\")\n",
    "        create_concat_file(joint_dir, joint_list, f\"{file_name}_cycle_\")\n",
    "        create_concat_file(drum_dot_dir, drum_dot_list, f\"{file_name}_cycle_\")\n",
    "        create_concat_file(dance_dot_dir, dance_dot_list, f\"{file_name}_cycle_\")\n",
    "    \n",
    "    def concatenate_videos(video_list, save_dir, save_name):\n",
    "        \n",
    "        concat_video = os.path.join(save_dir, f\"{save_name}.mp4\")\n",
    "        try:\n",
    "            result = subprocess.run([\n",
    "                'ffmpeg', '-y',\n",
    "                '-f', 'concat',\n",
    "                '-safe', '0',\n",
    "                '-i', video_list,\n",
    "                '-c', 'copy',\n",
    "                concat_video\n",
    "            ], capture_output=True, text=True)\n",
    "            if result.returncode != 0:\n",
    "                print(\"Error concatenating videos:\", result.stderr)\n",
    "                return\n",
    "        except Exception as e:\n",
    "            print(\"Error running ffmpeg:\", str(e))\n",
    "            return\n",
    "    \n",
    "    concatenate_videos(video_list, save_dir, f\"video_mix_concat\")\n",
    "    concatenate_videos(plot_list, save_dir, f\"plot_concat\")\n",
    "    concatenate_videos(joint_list, save_dir, f\"joint_{joint_name}_concat\")\n",
    "    \n",
    "    concatenate_videos(drum_dot_list, save_dir, f\"drum_dot_concat\")\n",
    "    concatenate_videos(dance_dot_list, save_dir, f\"dance_dot_concat\")\n",
    "    \n",
    "    concatenate_videos(front_view_list, save_dir, f\"front_view_concat\")\n",
    "    # concatenate_videos(left_view_list, save_dir, f\"left_view_concat\")\n",
    "    # concatenate_videos(right_view_list, save_dir, f\"right_view_concat\")\n",
    "    # concatenate_videos(top_view_list, save_dir, f\"top_view_concat\") \n",
    "\n",
    "    \n",
    "    # print(f\"Concatenated plot saved: {concat_plot}\")\n",
    "    # print(f\"Concatenated video saved: {concat_video}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joint_name = \"Hips\"\n",
    "\n",
    "vid_plot_path = os.path.join(\"composite_videos\", file_name, w_key)\n",
    "\n",
    "concatenate_and_overlay_videos(file_name, joint_name, vid_plot_path)        # modify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Composite Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_name = \"BKO_E1_D1_02_Maraka\"\n",
    "# w_key = \"beat_1\"\n",
    "# vid_plot_path = os.path.join(\"composite_videos\", file_name, w_key)\n",
    "\n",
    "concat_file_list = [f for f in os.listdir(vid_plot_path) if f.lower().endswith(\".mp4\")]\n",
    "concat_dict = {\n",
    "    f.replace('_concat.mp4', ''): os.path.join(vid_plot_path, f) \n",
    "    for f in concat_file_list\n",
    "}\n",
    "\n",
    "concat_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "def resize_video(video_path, width, height, save_dir):\n",
    "    \"\"\"\n",
    "    Resize a video to the specified width and height using ffmpeg,\n",
    "    with debug‐level output.\n",
    "\n",
    "    Parameters:\n",
    "    - video_path: str, path to the input video file\n",
    "    - width: int, target width in pixels\n",
    "    - height: int, target height in pixels\n",
    "    - save_dir: str, directory where the resized video will be saved\n",
    "\n",
    "    The output filename will be: <original_basename>_<width>x<height>.mp4\n",
    "    \"\"\"\n",
    "    # Ensure the save directory exists\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # Derive output filename from input basename\n",
    "    base_name = os.path.splitext(os.path.basename(video_path))[0]\n",
    "    output_filename = f\"{base_name}.mp4\"   # f\"{base_name}_{width}x{height}.mp4\"\n",
    "    output_path = os.path.join(save_dir, output_filename)\n",
    "\n",
    "    # Build ffmpeg command with debug-level logging\n",
    "    cmd = [\n",
    "        \"ffmpeg\",\n",
    "        \"-y\",                   # overwrite output if it exists\n",
    "        \"-loglevel\", \"debug\",   # show full debug output\n",
    "        \"-i\", video_path,\n",
    "        \"-vf\", f\"scale={width}:{height}\",\n",
    "        \"-c:v\", \"libx264\",\n",
    "        \"-crf\", \"18\",\n",
    "        \"-preset\", \"slow\",\n",
    "        output_path\n",
    "    ]\n",
    "\n",
    "    # Run ffmpeg and capture stdout/stderr\n",
    "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "\n",
    "    # Print debug output\n",
    "    # print(\"=== ffmpeg stdout ===\")\n",
    "    # print(result.stdout)\n",
    "    # print(\"=== ffmpeg stderr ===\")\n",
    "    # print(result.stderr)\n",
    "\n",
    "    # Check return code and report\n",
    "    if result.returncode == 0:\n",
    "        print(f\"Resizing succeeded, output saved to: {output_path}\")\n",
    "    else:\n",
    "        print(f\"ffmpeg failed with return code {result.returncode}\")\n",
    "\n",
    "    return output_path if result.returncode == 0 else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_videos = {\n",
    "    'video_mix': concat_dict['video_mix'],  \n",
    "    'plot': concat_dict['plot'],    \n",
    "    'front_view': concat_dict['front_view'],\n",
    "    'joint_Hips': concat_dict['joint_Hips'],\n",
    "    'drum_dot': concat_dict['drum_dot'],\n",
    "    'dance_dot': concat_dict['dance_dot'],\n",
    "    \n",
    "    # 'left_view': concat_dict['left_view'],\n",
    "    # 'right_view': concat_dict['right_view'],\n",
    "    # 'top_view': concat_dict['top_view'],\n",
    "}\n",
    "\n",
    "canvas_w, canvas_h = 1920, 1080 \n",
    "composite_layout_1 = [\n",
    "    # Top row - side by side\n",
    "    {'view': 'video_mix', 'x': 0, 'y': 0, 'width': 960, 'height': 540},\n",
    "    {'view': 'front_view', 'x': 960, 'y': 0, 'width': 960, 'height': 540},\n",
    "    \n",
    "    # Bottom row - stacked vertically\n",
    "    {'view': 'joint_Hips', 'x': 0, 'y': 540, 'width': 1920, 'height': 270},\n",
    "    {'view': 'plot', 'x': 0, 'y': 810, 'width': 1920, 'height': 270},\n",
    "]\n",
    "\n",
    "composite_layout_2 = [\n",
    "    # Top row - side by side\n",
    "    {'view': 'video_mix', 'x': 0, 'y': 0, 'width': 960, 'height': 540},\n",
    "    {'view': 'front_view', 'x': 960, 'y': 0, 'width': 960, 'height': 540},\n",
    "    \n",
    "    # Bottom row - stacked vertically\n",
    "    {'view': 'joint_Hips', 'x': 0, 'y': 540, 'width': 960, 'height': 270},\n",
    "    {'view': 'plot', 'x': 0, 'y': 810, 'width': 960, 'height': 270},\n",
    "    \n",
    "    # {'view': 'drum_dot', 'x': 960, 'y': 540, 'width': 960, 'height': 540},\n",
    "    {'view': 'drum_dot', 'x': 960, 'y': 540, 'width': 960, 'height': 270},\n",
    "    {'view': 'dance_dot', 'x': 960, 'y': 810, 'width': 960, 'height': 270},\n",
    "]\n",
    "\n",
    "\n",
    "saved_resized_dir = os.path.join(vid_plot_path, \"temp_resized\")\n",
    "os.makedirs(saved_resized_dir, exist_ok=True)\n",
    "\n",
    "composite_video_elements = []\n",
    "\n",
    "for video_element in composite_layout_2:\n",
    "    video_path = view_videos[video_element['view']]\n",
    "    v_width, v_height = video_element['width'], video_element['height']\n",
    "    x_pos_pxl, y_pos_pxl = video_element['x'], video_element['y']\n",
    "    \n",
    "    resized_path = resize_video(video_path, v_width, v_height, saved_resized_dir)\n",
    "    \n",
    "    composite_video_elements.append({\"view\": video_element['view'], \n",
    "                           \"vid_path\": resized_path,\n",
    "                           \"x_pos_pxl\": x_pos_pxl,\n",
    "                           \"y_pos_pxl\": y_pos_pxl,\n",
    "                           })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of dictionaries with just the paths and positions\n",
    "video_positions = []\n",
    "for element in composite_video_elements:\n",
    "    video_positions.append({\n",
    "        'path': element['vid_path'],\n",
    "        'x': element['x_pos_pxl'],\n",
    "        'y': element['y_pos_pxl']\n",
    "    })\n",
    "\n",
    "# Build the ffmpeg command\n",
    "ffmpeg_inputs = []\n",
    "for pos in video_positions:\n",
    "    ffmpeg_inputs.extend(['-i', pos['path']])\n",
    "\n",
    "# Create the xstack layout string\n",
    "# Format: xstack=inputs=4:layout=0_0|w0_0|0_h0|w0_h0\n",
    "layout = []\n",
    "for pos in video_positions:\n",
    "    layout.append(f\"{pos['x']}_{pos['y']}\")\n",
    "\n",
    "xstack_layout = \"|\".join(layout)\n",
    "\n",
    "final_out = os.path.join(vid_plot_path, \"final_output.mp4\")\n",
    "ffmpeg_cmd = [\n",
    "    'ffmpeg', '-y',\n",
    "    *ffmpeg_inputs,\n",
    "    '-filter_complex', f'xstack=inputs={len(video_positions)}:layout={xstack_layout}[v]',\n",
    "    '-map', '[v]',\n",
    "    '-map', '0:a?', '-c:a', 'aac', '-b:a', '192k',\n",
    "    '-c:v', 'libx264',   #'libx264',\n",
    "    '-crf', '23',\n",
    "    '-preset', 'ultrafast',\n",
    "    final_out\n",
    "]\n",
    "\n",
    "# Execute the command\n",
    "\n",
    "try:\n",
    "    subprocess.run(ffmpeg_cmd, check=True)\n",
    "    print(\"Video successfully created as final_output.mp4\")\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"Error creating video: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
