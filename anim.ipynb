{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped empty file: dance_onsets/BKO_E3_D6_10_Dansa_T/au/BKO_E3_D6_10_Dansa_T_Both_Feet_au_feet_onsets_all.csv\n"
     ]
    }
   ],
   "source": [
    "dance_dir_list = os.listdir(\"dance_onsets\")\n",
    "# fnm = dance_dir_list[0]\n",
    "\n",
    "for fnm in dance_dir_list:\n",
    "    dance_dir_au = f\"dance_onsets/{fnm}/au/{fnm}_Both_Feet_au_feet_onsets_all.csv\"\n",
    "    dance_dir_gr = f\"dance_onsets/{fnm}/gr/{fnm}_Both_Feet_gr_feet_onsets_all.csv\"\n",
    "    dance_dir_in = f\"dance_onsets/{fnm}/in/{fnm}_Both_Feet_in_feet_onsets_all.csv\"\n",
    "\n",
    "\n",
    "    # List to store all available onset values\n",
    "    all_onsets_list = []\n",
    "\n",
    "    # Read each available file and extend the list\n",
    "    for path in [dance_dir_au, dance_dir_gr, dance_dir_in]:\n",
    "        if os.path.exists(path):\n",
    "            try:\n",
    "                data = pd.read_csv(path)\n",
    "                if not data.empty:\n",
    "                    all_onsets_list.extend(data.iloc[:, 0].dropna().tolist())\n",
    "            except pd.errors.EmptyDataError:\n",
    "                print(f\"Skipped empty file: {path}\")\n",
    "\n",
    "    # Sort all onsets\n",
    "    all_onsets_sorted = sorted(all_onsets_list)\n",
    "\n",
    "    # Save to new CSV\n",
    "    output_path = f\"dance_onsets/{fnm}_dance_onsets.csv\"\n",
    "    pd.DataFrame(all_onsets_sorted, columns=[\"feet\"]).to_csv(output_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Add original names to the data\n",
    "data_with_original = [\n",
    "    (\"MISCHSALAT BEUT 250G\", \"Mixed salad bag 250g\", 2.95),\n",
    "    (\"POULETBRUSTLI\", \"Chicken breast slices\", 16.55),\n",
    "    (\"KÄGI BISCUITS 200G\", \"Kägi biscuits 200g\", 3.95),\n",
    "    (\"EIER 10 ST\", \"Eggs (10 pieces)\", 8.00),\n",
    "    (\"BM ERDNÜSSE 325G\", \"BM peanuts 325g\", 4.95),\n",
    "    (\"FS BRADFIRICH 0.5L\", \"Fruit beer or Radler 0.5L\", 2.35),\n",
    "    (\"FELDSCHLÖSSCHEN DOSE 50CL\", \"Feldschlösschen beer can 50cl\", 2.30),\n",
    "    (\"VOLG PIZZA MARGHER.\", \"Volg Margherita Pizza\", 3.85),\n",
    "    (\"Z CHIPS PAPRIKA 28G\", \"2 Paprika chips 28g\", 6.60),\n",
    "    (\"KNO ASIA CHICKEN 70G\", \"Knorr Asian Chicken 70g\", 6.80),\n",
    "    (\"RUCOLA SCHALE 100G\", \"Rocket (arugula) tray 100g\", 2.90),\n",
    "    (\"NEST CERV. BLÄTTERT\", \"Puff pastry or meat slices\", 5.20),\n",
    "    (\"AVOCADOS HASS\", \"Hass avocados\", 7.20),\n",
    "    (\"THON ROSE NAT 155G\", \"Canned pink tuna (natural) 155g\", 4.20),\n",
    "    (\"LINZERTORTE BÄCKEREI GRÄBER\", \"Linzertorte (Bakery Gräber)\", 16.00),\n",
    "    (\"VOLG FP FEL CH 10 ST\", \"Volg apples (10 pcs)\", 3.95),\n",
    "    (\"EIER 6 ST\", \"Eggs (6 pieces)\", 4.80),\n",
    "    (\"KÄSE\", \"Cheese\", 7.35),\n",
    "    (\"SCHWEINSSTEAK\", \"Pork steak\", 14.15),\n",
    "    (\"KÄSEREIBUTTER NÄFEN\", \"Dairy butter (Näfen)\", 3.90),\n",
    "    (\"SARDINEN IN ÖL 90G\", \"Sardines in oil 90g\", 1.85),\n",
    "    (\"CHAMPIGNON WEISS 250G\", \"White mushrooms 250g\", 3.60),\n",
    "    (\"VOLG FP NATURE 500G\", \"Volg yogurt, plain 500g\", 1.10),\n",
    "    (\"GRANINI FRUCHTCOCK TL\", \"Granini fruit cocktail drink\", 3.95)\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "df_csv = pd.DataFrame(data_with_original, columns=[\"Original Name\", \"Translated Name\", \"Price (CHF)\"])\n",
    "\n",
    "# Save to CSV\n",
    "csv_file_path = \"Swiss_Grocery_Bill_Translated.csv\"\n",
    "df_csv.to_csv(csv_file_path, index=False)\n",
    "\n",
    "# csv_file_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cleaned receipt data\n",
    "data = [\n",
    "    [\"Mozzarella râpée\", \"Grated mozzarella\", 3.19],\n",
    "    [\"Côtelettes cou porc\", \"Pork neck chops\", 5.99],\n",
    "    [\"Viande hachée de bœuf\", \"Minced beef\", 5.79],\n",
    "    [\"Mélange d'épices\", \"Spice mix\", 0.79],\n",
    "    [\"Avocat (1.25 x 5)\", \"Avocados (5 pcs)\", 6.25],\n",
    "    [\"Moser Bio Camembert\", \"Organic Camembert cheese\", 3.19],\n",
    "    [\"Rama Margarine\", \"Margarine\", 2.39],\n",
    "    [\"Capsules de café Gold Lu\", \"Gold Lu coffee capsules\", 4.69],\n",
    "    [\"JuraSel cuisine iodée & flu\", \"Iodized kitchen salt\", 1.05],\n",
    "    [\"Pâtes bio\", \"Organic pasta\", 1.19],\n",
    "    [\"Cottage Cheese High (1.65 x 3)\", \"Cottage cheese\", 4.95],\n",
    "    [\"Pain croustillant Bio\", \"Crunchy organic bread\", 2.99],\n",
    "    [\"Citron vert Fairtrade\", \"Fairtrade lime\", 0.55],\n",
    "    [\"Pommes rouges\", \"Red apples\", 1.67],\n",
    "    [\"Bananes\", \"Bananas\", 0.53],\n",
    "    [\"Pesto Bio\", \"Organic pesto\", 2.49],\n",
    "    [\"Pesto Bio\", \"Organic pesto\", 2.49],\n",
    "    [\"Hachis végétalien\", \"Vegan minced meat\", 2.99],\n",
    "    [\"Œufs élevage au sol\", \"Free-range eggs\", 4.25],\n",
    "    [\"Knorr Asia Quick Noo (1.89 x 5)\", \"Instant noodles\", 9.45],\n",
    "    [\"Oignons rouges bio\", \"Organic red onions\", 2.99],\n",
    "    [\"Émincé de poulet XXL\", \"XXL sliced chicken\", 8.99],\n",
    "    [\"Pain de mie\", \"Sandwich bread\", 1.19],\n",
    "    [\"Japansiche Sojasoße\", \"Japanese soy sauce\", 1.07],\n",
    "    [\"Cervelas au poulet\", \"Chicken sausage\", 3.69],\n",
    "    [\"Salade de jardinier\", \"Garden salad mix\", 1.59],\n",
    "    [\"Maggi Mix\", \"Maggi seasoning mix\", 2.35],\n",
    "    [\"Corona extra Bière 4.5%\", \"Corona Extra Beer 4.5%\", 10.49],\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data, columns=[\"Original (French/German)\", \"English Translation\", \"Price (CHF)\"])\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(\"Lidl_Receipt_Geneva.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Combined receipt data\n",
    "data = [\n",
    "    [\"Coop\", \"Flour Tortillas 480\", \"Flour Tortillas 480g\", 1, 2.00, 2.00],\n",
    "    [\"Coop\", \"Eier CH Bodenhaltung\", \"Swiss eggs (barn eggs)\", 1, 4.20, 4.20],\n",
    "    [\"Coop\", \"Zwiebeln gelb (0.230 kg)\", \"Yellow onions\", 0.230, 0.45, 0.45],\n",
    "    [\"Coop\", \"Blumenkohl\", \"Cauliflower\", 1, 4.25, 4.25],\n",
    "    [\"Coop\", \"Rispentomaten (0.225 kg)\", \"Vine tomatoes\", 0.225, 1.80, 1.80],\n",
    "    [\"Coop\", \"Red Kidney Beans 29\", \"Red kidney beans (can)\", 1, 1.70, 1.70],\n",
    "    [\"Coop\", \"Quick Noodles Curry\", \"Curry instant noodles\", 6, 1.90, 11.40],\n",
    "    [\"Coop\", \"Rabatt Knorr\", \"Knorr discount\", \"\", \"\", -2.40],\n",
    "    [\"Migros\", \"Badoit 1L\", \"Badoit sparkling water\", 1, 1.00, 1.00],\n",
    "    [\"Migros\", \"Bio Limes\", \"Organic limes\", 1, 2.50, 2.50]\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data, columns=[\"Store\", \"Original Item\", \"Translated Item\", \"Quantity\", \"Unit Price (CHF)\", \"Total (CHF)\"])\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(\"Coop_Lauterbrunnen_Migros_Geneva_Receipts.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['swiss\\\\Coop_Lauterbrunnen_Migros_Geneva_Receipts.csv',\n",
       " 'swiss\\\\Lidl_Receipt_Geneva.csv',\n",
       " 'swiss\\\\Volg_Receipt_Lauterbrunnen.csv.csv']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "glob.glob(r\"swiss\\\\*.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breakdown per person (CHF):\n",
      "Sharers\n",
      "Sagar    7.37\n",
      "Diego    7.37\n",
      "Maham    6.20\n",
      "Pedro    5.97\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# 1) configuration\n",
    "participants = [\"Sagar\", \"Diego\", \"Maham\", \"Pedro\"]\n",
    "\n",
    "# 2) helper to parse the “Person/Shared” cell\n",
    "def parse_sharers(cell):\n",
    "    cell = cell.strip()\n",
    "    if cell.lower() == \"shared\":\n",
    "        return participants.copy()\n",
    "    else:\n",
    "        return [name.strip() for name in cell.split(\",\")]\n",
    "\n",
    "# 3) read & concatenate\n",
    "all_dfs = []\n",
    "for path in glob.glob(r\"swiss\\\\*.csv\"):  # adjust to your folder\n",
    "    df_part = pd.read_csv(path, usecols=[\"Total (CHF)\", \"Person/Shared\"])\n",
    "    # ensure numeric\n",
    "    df_part[\"Total (CHF)\"] = pd.to_numeric(df_part[\"Total (CHF)\"], errors=\"raise\")\n",
    "    df_part[\"Sharers\"] = df_part[\"Person/Shared\"].apply(parse_sharers)\n",
    "    all_dfs.append(df_part)\n",
    "\n",
    "df = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "# 4) per-row share\n",
    "df[\"Share\"] = df.apply(lambda r: r[\"Total (CHF)\"] / len(r[\"Sharers\"]), axis=1)\n",
    "\n",
    "# 5) total expense\n",
    "total_expense = df[\"Total (CHF)\"].sum()\n",
    "\n",
    "# 6) explode & group\n",
    "df_exploded = df.explode(\"Sharers\")\n",
    "summary = (\n",
    "    df_exploded\n",
    "    .groupby(\"Sharers\")[\"Share\"]\n",
    "    .sum()\n",
    "    .reindex(participants, fill_value=0)\n",
    ")\n",
    "\n",
    "# 7) sanity check\n",
    "sum_of_shares = summary.sum()\n",
    "\n",
    "# 8) print everything\n",
    "# print(f\"Total expense (raw):       CHF {total_expense:.2f}\")\n",
    "# print(f\"Sum of individual shares:  CHF {sum_of_shares:.2f}\")\n",
    "# print(f\"Difference:               CHF {sum_of_shares - total_expense:.6f}\\n\")\n",
    "\n",
    "print(\"Breakdown per person (CHF):\")\n",
    "print(summary.round(2).to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who owes whom (CHF):\n",
      "creditor  Sagar\n",
      "debtor         \n",
      "Sagar      0.00\n",
      "Diego      7.37\n",
      "Maham      6.20\n",
      "Pedro      5.97\n",
      "\n",
      "Total expense credited by each payer (CHF):\n",
      "Paid_by\n",
      "Sagar    26.9\n",
      "Diego     0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# 1) configuration\n",
    "participants = [\"Sagar\", \"Diego\", \"Maham\", \"Pedro\"]\n",
    "\n",
    "# 2) helper to parse “Person/Shared”\n",
    "def parse_sharers(cell):\n",
    "    cell = cell.strip()\n",
    "    if cell.lower() == \"shared\":\n",
    "        return participants.copy()\n",
    "    else:\n",
    "        return [name.strip() for name in cell.split(\",\")]\n",
    "\n",
    "# 3) read & concat all CSVs\n",
    "all_rows = []\n",
    "for path in glob.glob(r\"swiss\\\\*.csv\"):  # adjust to your folder\n",
    "    df_part = pd.read_csv(path, usecols=[\"Total (CHF)\", \"Person/Shared\", \"Paid_by\"])\n",
    "    df_part[\"Total (CHF)\"] = pd.to_numeric(df_part[\"Total (CHF)\"], errors=\"raise\")\n",
    "    df_part[\"Sharers\"] = df_part[\"Person/Shared\"].apply(parse_sharers)\n",
    "    all_rows.append(df_part)\n",
    "df = pd.concat(all_rows, ignore_index=True)\n",
    "\n",
    "# 4) per‐row share\n",
    "df[\"Share\"] = df[\"Total (CHF)\"] / df[\"Sharers\"].str.len()\n",
    "\n",
    "# 5) build raw debt records\n",
    "records = []\n",
    "for _, row in df.iterrows():\n",
    "    payer = row[\"Paid_by\"]\n",
    "    for sharer in row[\"Sharers\"]:\n",
    "        if sharer != payer:\n",
    "            records.append({\n",
    "                \"debtor\":   sharer,\n",
    "                \"creditor\": payer,\n",
    "                \"amount\":   row[\"Share\"]\n",
    "            })\n",
    "debts = pd.DataFrame(records)\n",
    "\n",
    "# 6) summarize into a debts‐matrix\n",
    "debts_summary = (\n",
    "    debts\n",
    "    .groupby([\"debtor\", \"creditor\"])[\"amount\"]\n",
    "    .sum()\n",
    "    .reset_index()\n",
    ")\n",
    "creditors = debts_summary[\"creditor\"].unique().tolist()\n",
    "\n",
    "debts_matrix = (\n",
    "    debts_summary\n",
    "    .pivot(index=\"debtor\", columns=\"creditor\", values=\"amount\")\n",
    "    .fillna(0)\n",
    "    .reindex(index=participants, columns=creditors, fill_value=0)\n",
    ")\n",
    "\n",
    "# 7) total expense credited by Sagar & Diego\n",
    "total_by_payer = (\n",
    "    df\n",
    "    .groupby(\"Paid_by\")[\"Total (CHF)\"]\n",
    "    .sum()\n",
    "    .reindex([\"Sagar\", \"Diego\"], fill_value=0)\n",
    ")\n",
    "\n",
    "# 8) output\n",
    "print(\"Who owes whom (CHF):\")\n",
    "print(debts_matrix.round(2).to_string())\n",
    "\n",
    "print(\"\\nTotal expense credited by each payer (CHF):\")\n",
    "print(total_by_payer.round(2).to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creditors (unique payers): ['Sagar', 'Diego', 'Pedro']\n",
      "\n",
      "Who owes whom (CHF):\n",
      "creditor  Sagar  Diego  Pedro\n",
      "debtor                       \n",
      "Sagar      0.00  23.21  21.90\n",
      "Diego      7.37   0.00  33.80\n",
      "Maham      6.20  20.54  21.15\n",
      "Pedro      5.97  26.33   0.00\n",
      "\n",
      "Total expense credited by each payer (CHF):\n",
      "Paid_by\n",
      "Sagar     26.90\n",
      "Diego     99.24\n",
      "Pedro    138.45\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# 1) configuration\n",
    "participants = [\"Sagar\", \"Diego\", \"Maham\", \"Pedro\"]\n",
    "\n",
    "# 2) helper to parse “Person/Shared”\n",
    "def parse_sharers(cell):\n",
    "    cell = cell.strip()\n",
    "    if cell.lower() == \"shared\":\n",
    "        return participants.copy()\n",
    "    else:\n",
    "        return [name.strip() for name in cell.split(\",\")]\n",
    "\n",
    "# 3) read & concat all CSVs\n",
    "all_rows = []\n",
    "for path in glob.glob(r\"swiss\\\\*.csv\"):  # adjust to your folder\n",
    "    df_part = pd.read_csv(path, usecols=[\"Total (CHF)\", \"Person/Shared\", \"Paid_by\"])\n",
    "    df_part[\"Total (CHF)\"] = pd.to_numeric(df_part[\"Total (CHF)\"], errors=\"raise\")\n",
    "    df_part[\"Sharers\"] = df_part[\"Person/Shared\"].apply(parse_sharers)\n",
    "    all_rows.append(df_part)\n",
    "df = pd.concat(all_rows, ignore_index=True)\n",
    "\n",
    "# 4) extract actual creditors from the Paid_by column\n",
    "creditors = df[\"Paid_by\"].unique().tolist()\n",
    "print(\"Creditors (unique payers):\", creditors)\n",
    "\n",
    "# 5) per‐row share\n",
    "df[\"Share\"] = df[\"Total (CHF)\"] / df[\"Sharers\"].str.len()\n",
    "\n",
    "# 6) build raw debt records\n",
    "records = []\n",
    "for _, row in df.iterrows():\n",
    "    payer = row[\"Paid_by\"]\n",
    "    for sharer in row[\"Sharers\"]:\n",
    "        if sharer != payer:\n",
    "            records.append({\n",
    "                \"debtor\":   sharer,\n",
    "                \"creditor\": payer,\n",
    "                \"amount\":   row[\"Share\"]\n",
    "            })\n",
    "debts = pd.DataFrame(records)\n",
    "\n",
    "# 7) summarize into a debts‐matrix\n",
    "debts_summary = (\n",
    "    debts\n",
    "    .groupby([\"debtor\", \"creditor\"])[\"amount\"]\n",
    "    .sum()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "debts_matrix = (\n",
    "    debts_summary\n",
    "    .pivot(index=\"debtor\", columns=\"creditor\", values=\"amount\")\n",
    "    .fillna(0)\n",
    "    .reindex(index=participants, columns=creditors, fill_value=0)\n",
    ")\n",
    "\n",
    "# 8) total expense credited by each actual payer\n",
    "total_by_payer = (\n",
    "    df\n",
    "    .groupby(\"Paid_by\")[\"Total (CHF)\"]\n",
    "    .sum()\n",
    "    .reindex(creditors, fill_value=0)\n",
    ")\n",
    "\n",
    "# 9) output\n",
    "print(\"\\nWho owes whom (CHF):\")\n",
    "print(debts_matrix.round(2).to_string())\n",
    "\n",
    "print(\"\\nTotal expense credited by each payer (CHF):\")\n",
    "print(total_by_payer.round(2).to_string())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
