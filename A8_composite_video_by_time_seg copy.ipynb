{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import subprocess\n",
    "# import pandas as pd\n",
    "from utils_mocap_viz.generate_views import (    # organize this\n",
    "    # get_output_dir,\n",
    "    prepare_videos\n",
    ")\n",
    "\n",
    "from utils_mocap_viz.animated_merged_phase_analysis import animate_merged_phase_analysis, animate_merged_phase_analysis_with_user_window\n",
    "from utils_dance_anim.dance_dot import animate_dance_phase_analysis\n",
    "from utils_pipeline.pipeline_B import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dance Mode: group\n",
      "Mode start time: 23.16\n",
      "Mode end time: 65.20\n"
     ]
    }
   ],
   "source": [
    "file_name = \"BKO_E1_D1_02_Maraka\"\n",
    "traj_dir  = \"traj_files_presentation\"\n",
    "status    = \"included\"   # or \"excluded\"\n",
    "traj_threshold = \"0.001\"        # or any other threshold\n",
    "\n",
    "bvh_dir = os.path.join(\"data\", \"bvh_files\")\n",
    "bvh_file = os.path.join(bvh_dir, file_name + \"_T\")\n",
    "\n",
    "# path to onsets and cycles csv files\n",
    "cycles_csv_path = f\"data/virtual_cycles/{file_name}_C.csv\"\n",
    "onsets_csv_path = f\"data/drum_onsets/{file_name}.csv\"\n",
    "dance_csv_path = f\"data/dance_onsets/{file_name}_T_dance_onsets.csv\"\n",
    "\n",
    "\n",
    "m_idx = 0\n",
    "mode = [\"group\", \"individual\", \"audience\"]\n",
    "dance_mode = mode[m_idx]\n",
    "\n",
    "motion_data_dir = \"data/motion_data_pkl\"\n",
    "dance_mode_path = f\"data/dance_modes_ts/{file_name}_{dance_mode}.pkl\"\n",
    "\n",
    "# load dance mode time segments\n",
    "if os.path.exists(dance_mode_path):\n",
    "    with open(dance_mode_path, \"rb\") as f:\n",
    "        dmode_ts = pickle.load(f)\n",
    "else:\n",
    "    print(f\"{file_name} {dance_mode} does not exist\")\n",
    "\n",
    "\n",
    "mode_start_time, mode_end_time = dmode_ts[0]\n",
    "\n",
    "print(\"Dance Mode:\", dance_mode)\n",
    "print(f\"Mode start time: {mode_start_time:.2f}\")\n",
    "print(f\"Mode end time: {mode_end_time:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(31.07633333333333, 33.48166666633333, 0),\n",
       " (33.48166666633333, 35.851444444, 0),\n",
       " (35.851444444, 38.19277777766667, 0),\n",
       " (38.19277777766667, 40.538555555, 0),\n",
       " (40.538555555, 42.90566666666667, 0)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = 30\n",
    "end_time = 45\n",
    "\n",
    "cyc_df = pd.read_csv(cycles_csv_path)\n",
    "cycle_onsets = cyc_df[\"Virtual Onset\"].values\n",
    "cycle_onsets_in_range = cycle_onsets[(cycle_onsets >= start_time) & (cycle_onsets <= end_time)] \n",
    "\n",
    "\n",
    "traj_tuples = [ (cycle_onsets_in_range[i], cycle_onsets_in_range[i+1], 0) for i in range(len(cycle_onsets_in_range)-1)]\n",
    "traj_tuples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate trajectory video + trimmed dance video plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vid_plot_path = f\"cycle_videos/{file_name}/\"\n",
    "# start_time = 30\n",
    "# end_time = 60\n",
    "# traj_tuples = [(start_time, end_time, 0)]\n",
    "\n",
    "base_output_dir = os.path.join(\"composite_videos\", f\"{file_name}_{start_time:.2f}_{end_time:.2f}\")\n",
    "os.makedirs(base_output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_forward_cycle_videos_and_plots(\n",
    "    file_name = file_name,\n",
    "    windows = traj_tuples,  # List of (win_start, win_end, t_poi) tuples\n",
    "    base_path_logs = \"data/logs_v4_0.007_foot_jun3\",            # logs_v4_0.007_foot_jun3       logs_v2_may\n",
    "    figsize = (10, 3),\n",
    "    dpi = 200,\n",
    "    save_dir = base_output_dir,\n",
    "    legend_flag = True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating animation for drum merged dot plot for BKO_E1_D1_02_Maraka\n",
      "Full window: 23.2s - 65.2s\n",
      "Animation window: 30.0s - 45.0s\n",
      "Total onsets: 1830\n",
      "Onsets in window 23.16s - 65.2s: 111\n",
      "Total onsets: 1830\n",
      "Onsets in window 23.16s - 65.2s: 204\n",
      "Total onsets: 1830\n",
      "Onsets in window 23.16s - 65.2s: 144\n",
      "\n",
      "Creating animation...\n",
      "Animation will have 360 frames\n",
      "Time range: 30.00s - 44.96s\n",
      "\n",
      "Saving animation to: composite_videos\\BKO_E1_D1_02_Maraka_30.00_45.00\\drum_dot_merged\\drum_dot_merged_23.16_65.20.mp4\n",
      "Animation saved successfully!\n"
     ]
    }
   ],
   "source": [
    "output_dir3 = os.path.join(base_output_dir, \"drum_dot_merged\")\n",
    "os.makedirs(output_dir3, exist_ok=True)\n",
    "\n",
    "output_dir4 = os.path.join(base_output_dir, \"dance_dot\")\n",
    "os.makedirs(output_dir4, exist_ok=True)\n",
    "\n",
    "anim = animate_merged_phase_analysis_with_user_window(\n",
    "    file_name= file_name,\n",
    "    W_start= mode_start_time,\n",
    "    W_end= mode_end_time,\n",
    "    user_start= start_time,\n",
    "    user_end= end_time,\n",
    "    cycles_csv_path= cycles_csv_path,\n",
    "    onsets_csv_path= onsets_csv_path,\n",
    "    save_dir=output_dir3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Skeletal video + trimmed_video_mix + drum dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video_path = os.path.join(\"data\", \"videos\", f\"{file_name}_pre_R_Mix.mp4\")\n",
    "\n",
    "output_dir1 = os.path.join(base_output_dir, \"video_skeleton\")\n",
    "os.makedirs(output_dir1, exist_ok=True)\n",
    "\n",
    "output_dir3 = os.path.join(base_output_dir, \"drum_dot_merged\")\n",
    "os.makedirs(output_dir3, exist_ok=True)\n",
    "\n",
    "output_dir4 = os.path.join(base_output_dir, \"dance_dot\")\n",
    "os.makedirs(output_dir4, exist_ok=True)\n",
    "\n",
    "views_to_generate = ['front']       # skeleton views ['front', 'right' 'left', 'top'] \n",
    "\n",
    "for start_time, end_time, _ in traj_tuples:\n",
    "\n",
    "    # save_fname = f\"drum_dot_merged_{start_time:.2f}_{end_time:.2f}.mp4\"\n",
    "    \n",
    "    # Merged Drum dot plot video\n",
    "    animate_merged_phase_analysis(\n",
    "        file_name, \n",
    "        start_time, \n",
    "        end_time,\n",
    "        cycles_csv_path, \n",
    "        onsets_csv_path,\n",
    "        figsize=(10, 3), dpi=200,\n",
    "        # save_fname = save_fname,\n",
    "        save_dir=output_dir3,\n",
    "        legend_flag = True,\n",
    "        )\n",
    "    \n",
    "    # Dance dot plot video\n",
    "    animate_dance_phase_analysis(       \n",
    "        file_name, start_time, end_time,\n",
    "        cycles_csv_path, dance_csv_path,\n",
    "        figsize= (10, 3), \n",
    "        dpi= 200, \n",
    "        save_dir= output_dir4,\n",
    "        )\n",
    "\n",
    "    # Generate Skeleton views\n",
    "    view_videos = prepare_videos(\n",
    "        filename= bvh_file,\n",
    "        start_time= start_time,\n",
    "        end_time= end_time,\n",
    "        views_to_generate = views_to_generate,\n",
    "        video_path= None,             # video_path, wont generate video\n",
    "        video_size= (1280, 720),\n",
    "        fps= 24,\n",
    "        output_dir = output_dir1\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate animated kinematic plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_kinematic_cycle_plots(\n",
    "    file_name: str,\n",
    "    windows: list,  # List of (win_start, win_end, t_poi) tuples\n",
    "    joint_name: str,\n",
    "    axis: str = 'y',\n",
    "    base_path_logs: str = \"data/logs_v2_may\",\n",
    "    frame_rate: float = 240,  # Trajectory data frame rate\n",
    "    n_beats_per_cycle: int = 4,\n",
    "    n_subdiv_per_beat: int = 3,\n",
    "    nn: int = 3,\n",
    "    output_dir2: str = None,\n",
    "    figsize: tuple = (10, 3),\n",
    "    dpi: int = 200,\n",
    "    legend_flag: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Create trajectory animations for windows around points of interest (beats or subdivisions).\n",
    "    Each plot shows [-cycle, 0-cycle, +cycle] around the POI.\n",
    "    \"\"\"\n",
    "    # Create save directory if not provided\n",
    "    # if output_dir2 is None:\n",
    "    #     output_dir2 = os.path.join(\"cycle_plots\", file_name, window_key, joint_name)\n",
    "    #     os.makedirs(output_dir2, exist_ok=True)\n",
    "    \n",
    "    bvh_to_mvnx = {\n",
    "    'x': 'y',  # BVH side → MVNX side\n",
    "    'y': 'z',  # BVH vertical → MVNX vertical\n",
    "    'z': 'x',  # BVH forward → MVNX forward\n",
    "    }\n",
    "    \n",
    "    \n",
    "    # Load joint position data\n",
    "    dir_csv = \"extracted_mocap_csv\"\n",
    "    base_name = os.path.splitext(os.path.basename(file_name))[0]\n",
    "    worldpos_file = os.path.join(dir_csv, f\"{base_name}_T_worldpos.csv\")\n",
    "    \n",
    "    try:\n",
    "        world_positions = pd.read_csv(worldpos_file)\n",
    "        print(f\"Successfully loaded CSV with {len(world_positions)} rows\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading CSV file: {e}\")\n",
    "        raise\n",
    "    \n",
    "    # Get time column and position data\n",
    "    time_column = world_positions.columns[0]  # First column is time\n",
    "    times = world_positions[time_column].values\n",
    "    positions = world_positions[f\"{joint_name}.{axis.upper()}\"].values\n",
    "    \n",
    "    print(f\"\\nProcessing {len(windows)} windows\")\n",
    "    # print(f\"Total frames in trajectory data: {len(times)}\")\n",
    "    # print(f\"Time range in trajectory data: {times[0]:.3f} to {times[-1]:.3f}\")\n",
    "    \n",
    "    # Process each window or cycle\n",
    "    for i, (win_start, win_end, _) in enumerate(windows):  # Removed t_poi\n",
    "        print(f\"\\nProcessing window {i+1}:\")\n",
    "        print(f\"  Window time range: {win_start:.3f} to {win_end:.3f}\")\n",
    "        \n",
    "        # Calculate segment times\n",
    "        start_time = win_start\n",
    "        end_time = win_end\n",
    "        duration = end_time - start_time\n",
    "        \n",
    "        # Calculate window parameters\n",
    "        beat_len = duration / n_beats_per_cycle\n",
    "        subdiv_len = beat_len / n_subdiv_per_beat\n",
    "        half_win = subdiv_len * nn\n",
    "        \n",
    "        # Calculate frame numbers for trajectory (240fps)\n",
    "        traj_start_frame = int(start_time * frame_rate)\n",
    "        traj_end_frame = int(end_time * frame_rate)\n",
    "        traj_n_frames = traj_end_frame - traj_start_frame\n",
    "        \n",
    "        print(f\"  Trajectory frames: {traj_start_frame} to {traj_end_frame} (240fps)\")\n",
    "        \n",
    "        # Check if we have valid frame numbers\n",
    "        if traj_start_frame >= traj_end_frame:\n",
    "            print(f\"  Skipping window {i+1}: Invalid frame range (start >= end)\")\n",
    "            continue\n",
    "        if traj_start_frame < 0:\n",
    "            print(f\"  Skipping window {i+1}: Start frame < 0\")\n",
    "            continue\n",
    "        if traj_end_frame > len(positions):\n",
    "            print(f\"  Skipping window {i+1}: End frame > total frames\")\n",
    "            continue\n",
    "        \n",
    "        # Trim trajectory data using frame numbers at 240fps\n",
    "        pos_win = positions[traj_start_frame:traj_end_frame]\n",
    "        t_win = times[traj_start_frame:traj_end_frame]\n",
    "        \n",
    "        # Check if we have valid trajectory data\n",
    "        if len(pos_win) == 0:\n",
    "            print(f\"  Skipping window {i+1}: No trajectory data\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"  Trajectory data points: {len(pos_win)}\")\n",
    "        \n",
    "        # Create figure and axis ------------------------------------------------------------------------\n",
    "        fig, ax = plt.subplots(figsize=figsize, dpi=dpi)\n",
    "        fig.tight_layout(pad=2.0) \n",
    "        \n",
    "        # Calculate all subdivision times for the window\n",
    "        all_subdiv_times = []\n",
    "        for beat_idx in range(0, n_beats_per_cycle + 1):  # Changed: now starts from 0\n",
    "            beat_time = start_time + beat_idx * beat_len  # Changed: use start_time instead of downbeat\n",
    "            for subdiv_idx in range(n_subdiv_per_beat):\n",
    "                subdiv_time = beat_time + subdiv_idx * subdiv_len\n",
    "                if start_time <= subdiv_time <= end_time:\n",
    "                    all_subdiv_times.append((subdiv_time, beat_idx * n_subdiv_per_beat + subdiv_idx + 1))\n",
    "\n",
    "        # Plot subdivision lines with appropriate colors\n",
    "        for subdiv_time, subdiv_num in all_subdiv_times:\n",
    "            color = get_subdiv_color(subdiv_num)\n",
    "            if subdiv_num in [1, 4, 7, 10, 13]:\n",
    "                ax.axvline(subdiv_time, color=color, linestyle='-', linewidth=2, alpha=0.7) #beat color\n",
    "            else:\n",
    "                ax.axvline(subdiv_time, color=color, linestyle='--', linewidth=1, alpha=0.3) #subdivision color\n",
    "        \n",
    "        # Plot trajectory\n",
    "        ax.plot(t_win, pos_win, '-', color='green', alpha=0.5, label=f'{joint_name} {axis.upper()}')\n",
    "        \n",
    "        # Set y-axis limits with safety checks\n",
    "        try:\n",
    "            y_min = pos_win.min()\n",
    "            y_max = pos_win.max()\n",
    "            y_range = y_max - y_min\n",
    "            ax.set_ylim(y_min - 0.1*y_range, y_max + 0.1*y_range)\n",
    "        except ValueError as e:\n",
    "            print(f\"  Warning: Could not set y-axis limits: {e}\")\n",
    "            ax.set_ylim(-1, 1)\n",
    "        \n",
    "        # Create vertical playhead\n",
    "        v_playhead, = ax.plot([start_time, start_time], \n",
    "                            [y_min - 0.1*y_range, y_max + 0.1*y_range],\n",
    "                            lw=1.5, alpha=0.9, color='orange')\n",
    "        \n",
    "        # Set up the plot with scaled x-axis\n",
    "        ax.set_xlabel(f'Beat span')\n",
    "        ax.set_ylabel(f'{joint_name} {bvh_to_mvnx[axis.lower()]} Position')      # {axis.upper()} y is vertical in bvh files, Z is vertical in mocap\n",
    "        ax.set_title(f'{file_name} | Window:{start_time:.2f}s - {end_time:.2f}| Time: {start_time:.2f}s')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Scale x-axis to show beats instead of cycles\n",
    "        x_ticks = np.arange(1, n_beats_per_cycle + 2)  # Changed: now 1 to 5\n",
    "        x_tick_positions = start_time + (x_ticks - 1) * beat_len  # Changed: use start_time and adjust for 1-based indexing\n",
    "        ax.set_xticks(x_tick_positions)\n",
    "        ax.set_xticklabels(x_ticks)\n",
    "        ax.set_xlim(start_time, end_time)\n",
    "        \n",
    "        # Add legend\n",
    "        custom = [\n",
    "            Line2D([0],[0], color='green', lw=1.5),\n",
    "            Line2D([0],[0], color='black', lw=1),\n",
    "            Line2D([0],[0], color='green', lw=1, linestyle='--'),\n",
    "            Line2D([0],[0], color='red', lw=1, linestyle='--'),\n",
    "        ]\n",
    "        labels = [\n",
    "            f\"{joint_name} {axis.upper()}\", \n",
    "            \"Subdiv-1 (1,4,7,10)\", \n",
    "            \"Subdiv-2 (2,5,8,11)\", \n",
    "            \"Subdiv-3 (3,6,9,12)\"\n",
    "        ]\n",
    "        \n",
    "        if legend_flag:\n",
    "            ax.legend(custom, labels, loc='upper left', framealpha=0.3, fontsize=6)\n",
    "        \n",
    "        def update(frame):\n",
    "            v_playhead.set_xdata([frame, frame])\n",
    "            ax.set_title(f'{file_name} | Window:{start_time:.2f}s - {end_time:.2f}s| Time: {frame:.2f}s')\n",
    "            return v_playhead,\n",
    "        \n",
    "        # Create animation frames at 24fps\n",
    "        # n_frames = int(duration * 24)           # \n",
    "        # frames = np.linspace(start_time, end_time, n_frames)\n",
    "        \n",
    "        frames = np.arange(start_time, end_time, 1/24)      # New 06 June 2025\n",
    "        anim = animation.FuncAnimation(\n",
    "            fig, update, frames=frames,\n",
    "            interval=1000/24,  # 24fps\n",
    "            blit=True\n",
    "        )\n",
    "        \n",
    "        # Save animation\n",
    "        plot_output_path = os.path.join(output_dir2, f\"{file_name}_window_{i+1:03d}_{start_time:.2f}_{end_time:.2f}.mp4\")\n",
    "        writer = animation.FFMpegWriter(fps= 24, \n",
    "                                        bitrate=2000,\n",
    "                                        codec='libx264',  # Specify codec\n",
    "                                        # extra_args=['-preset', 'ultrafast']\n",
    "                                        )  # 24fps\n",
    "        anim.save(plot_output_path, writer=writer)\n",
    "        plt.close(fig)\n",
    "        \n",
    "        print(f\"Plot saved: {plot_output_path}\")\n",
    "        print(f\"Plot duration: {len(frames)/24:.3f}s\")\n",
    "    \n",
    "    print(\"\\nProcessing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Available markers: ['Hips', 'LeftHip', 'LeftKnee', 'LeftAnkle', 'LeftToe', \n",
    "# 'LeftToeEnd', 'RightHip', 'RightKnee', 'RightAnkle', 'RightToe', 'RightToeEnd', \n",
    "# 'Chest', 'Chest2', 'Chest3', 'Chest4', 'LeftCollar', 'LeftShoulder', 'LeftElbow', \n",
    "# 'LeftWrist', 'LeftWristEnd', 'RightCollar', 'RightShoulder', 'RightElbow', \n",
    "# 'RightWrist', 'RightWristEnd', 'Neck', 'Head', 'HeadEnd']\n",
    "\n",
    "mvnx_to_bvh = {\n",
    "    'x': 'z',  # forward mvnx → backward bvh\n",
    "    'y': 'x',  # side mvnx → side bvh\n",
    "    'z': 'y',  # vertical mvnx → vertical bvh\n",
    "}\n",
    "\n",
    "joint_name = \"Hips\"  \n",
    "axis = 'z'      # z is vertical in mvnx files\n",
    "\n",
    "output_dir2 = os.path.join(base_output_dir, joint_name)\n",
    "os.makedirs(output_dir2, exist_ok=True)\n",
    "\n",
    "extract_kinematic_cycle_plots(\n",
    "file_name= file_name,\n",
    "windows= traj_tuples,\n",
    "joint_name= joint_name,\n",
    "axis= mvnx_to_bvh[axis],\n",
    "output_dir2= output_dir2,\n",
    "figsize = (10, 3),  # 2000 x 600 px\n",
    "dpi= 200,\n",
    "legend_flag = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare for concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_category(filename):\n",
    "    \"\"\"\n",
    "    Given a filename like \"front_view_56.7_61.2.mp4\" or\n",
    "    \"BKO_E1_D1_02_Maraka_pre_R_Mix_trimmed_56.7_61.2.mp4\",\n",
    "    return the category portion before the last two underscore-separated tokens.\n",
    "    \"\"\"\n",
    "    name, _ = os.path.splitext(filename)     # strip .mp4\n",
    "    parts = name.split('_')\n",
    "    # Last two parts are start and end times, so category is everything before them\n",
    "    if len(parts) > 2:\n",
    "        return \"_\".join(parts[:-2])\n",
    "    return name   # fallback if unexpected format\n",
    "\n",
    "def write_all_categories(files, output_dir, video_dir):\n",
    "    \"\"\"\n",
    "    From a list of filenames, group by category (as defined by extract_category),\n",
    "    and write each group into its own .txt file in output_dir.\n",
    "    \"\"\"\n",
    "    # os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Group filenames by category\n",
    "    categories = {}\n",
    "    for fname in files:\n",
    "        cat = extract_category(fname)\n",
    "        categories.setdefault(cat, []).append(fname)\n",
    "\n",
    "    # Write each category's filenames to a separate text file\n",
    "    for cat, fnames in categories.items():\n",
    "        txt_path = os.path.join(output_dir, f\"{cat}.txt\")\n",
    "        with open(txt_path, \"w\") as fw:\n",
    "            for f in fnames:\n",
    "                if video_dir:\n",
    "                    rel_path = os.path.relpath(os.path.join(video_dir, f), os.path.dirname(txt_path))\n",
    "                    fw.write(f\"file '{rel_path}'\\n\")\n",
    "                else:\n",
    "                    fw.write(f + \"\\n\")  \n",
    "                \n",
    "\n",
    "def create_concat_file(video_dir, output_file, prefix):\n",
    "    \"\"\"Create a text file listing all videos in order for concatenation\"\"\"\n",
    "    with open(output_file, 'w') as f:\n",
    "        # Get all video files and sort them\n",
    "        video_files = sorted([f for f in os.listdir(video_dir) if f.endswith('.mp4')])\n",
    "        # Write each file path - use relative path from the text file location\n",
    "        for video in video_files:\n",
    "            # Get relative path from output_file to video_dir\n",
    "            rel_path = os.path.relpath(os.path.join(video_dir, video), os.path.dirname(output_file))\n",
    "            f.write(f\"file '{rel_path}'\\n\") \n",
    "            \n",
    "def concatenate_and_overlay_videos(file_name, joint_name,  save_dir, views_to_generate):\n",
    "    \"\"\"Concatenate cycle videos and plot videos, then overlay them\"\"\"\n",
    "    video_dir = os.path.join(save_dir, \"videos\")\n",
    "    plot_dir = os.path.join(save_dir, \"plots\")\n",
    "    joint_dir = os.path.join(save_dir, joint_name)\n",
    "    vid_skel_dir = os.path.join(save_dir, \"video_skeleton\")\n",
    "    drum_dot_dir = os.path.join(save_dir, \"drum_dot_merged\")\n",
    "    dance_dot_dir = os.path.join(save_dir, \"dance_dot\")\n",
    "\n",
    "    # Create text files for concatenation\n",
    "    video_list = os.path.join(save_dir, \"video_list.txt\")\n",
    "    plot_list = os.path.join(save_dir, \"plot_list.txt\")\n",
    "    joint_list = os.path.join(save_dir, \"joint_list.txt\")\n",
    "    \n",
    "    drum_dot_list = os.path.join(save_dir, \"drum_dot_list.txt\")\n",
    "    dance_dot_list = os.path.join(save_dir, \"dance_dot_list.txt\")\n",
    "    \n",
    "    # 'front', 'right' 'left', 'top'\n",
    "    if 'front' in views_to_generate:\n",
    "        front_view_list = os.path.join(save_dir, \"front_view.txt\")\n",
    "    if 'left' in views_to_generate:\n",
    "        left_view_list = os.path.join(save_dir, \"left_view.txt\")\n",
    "    if 'right' in views_to_generate:\n",
    "        right_view_list = os.path.join(save_dir, \"right_view.txt\")\n",
    "    if 'top' in views_to_generate:\n",
    "        top_view_list = os.path.join(save_dir, \"top_view.txt\")\n",
    "    \n",
    "    \n",
    "    mp4_file_list = [f for f in os.listdir(vid_skel_dir) if f.lower().endswith(\".mp4\")]\n",
    "    write_all_categories(mp4_file_list, save_dir, video_dir = vid_skel_dir)\n",
    "    \n",
    "    \n",
    "    # Check if directories exist\n",
    "    if not os.path.exists(video_dir):\n",
    "        print(f\"Video directory not found: {video_dir}\")\n",
    "        return\n",
    "    if not os.path.exists(plot_dir):\n",
    "        print(f\"Plot directory not found: {plot_dir}\")\n",
    "        return\n",
    "        \n",
    "    # Check if text files already exist\n",
    "    if os.path.exists(video_list) and os.path.exists(plot_list):\n",
    "        print(\"Concatenation files already exist, skipping creation\")\n",
    "    else:\n",
    "        print(\"Creating concatenation files...\")\n",
    "        create_concat_file(video_dir, video_list, f\"{file_name}_cycle_\")\n",
    "        create_concat_file(plot_dir, plot_list, f\"{file_name}_cycle_\")\n",
    "        create_concat_file(joint_dir, joint_list, f\"{file_name}_cycle_\")\n",
    "        create_concat_file(drum_dot_dir, drum_dot_list, f\"{file_name}_cycle_\")\n",
    "        create_concat_file(dance_dot_dir, dance_dot_list, f\"{file_name}_cycle_\")\n",
    "    \n",
    "    def concatenate_videos(video_list, save_dir, save_name):\n",
    "        \n",
    "        concat_video = os.path.join(save_dir, f\"{save_name}.mp4\")\n",
    "        try:\n",
    "            result = subprocess.run([\n",
    "                'ffmpeg', '-y',\n",
    "                '-f', 'concat',\n",
    "                '-safe', '0',\n",
    "                '-i', video_list,\n",
    "                '-c', 'copy',\n",
    "                concat_video\n",
    "            ], capture_output=True, text=True)\n",
    "            if result.returncode != 0:\n",
    "                print(\"Error concatenating videos:\", result.stderr)\n",
    "                return\n",
    "        except Exception as e:\n",
    "            print(\"Error running ffmpeg:\", str(e))\n",
    "            return\n",
    "    \n",
    "    concatenate_videos(video_list, save_dir, f\"video_mix_concat\")\n",
    "    concatenate_videos(plot_list, save_dir, f\"plot_concat\")\n",
    "    concatenate_videos(joint_list, save_dir, f\"joint_{joint_name}_concat\")\n",
    "    \n",
    "    concatenate_videos(drum_dot_list, save_dir, f\"drum_dot_concat\")\n",
    "    concatenate_videos(dance_dot_list, save_dir, f\"dance_dot_concat\")\n",
    "    \n",
    "    if 'front' in views_to_generate:    \n",
    "        concatenate_videos(front_view_list, save_dir, f\"front_view_concat\")\n",
    "    if 'left' in views_to_generate:\n",
    "        concatenate_videos(left_view_list, save_dir, f\"left_view_concat\")\n",
    "    if 'right' in views_to_generate:\n",
    "        concatenate_videos(right_view_list, save_dir, f\"right_view_concat\")\n",
    "    if 'top' in views_to_generate:\n",
    "        concatenate_videos(top_view_list, save_dir, f\"top_view_concat\") \n",
    "\n",
    "    \n",
    "    print(f\"Concatenation complete: {save_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenate_and_overlay_videos(file_name, joint_name, base_output_dir, views_to_generate)        # modify\n",
    "\n",
    "concat_file_list = [f for f in os.listdir(base_output_dir) if f.lower().endswith(\".mp4\")]\n",
    "concat_dict = {\n",
    "    f.replace('_concat.mp4', ''): os.path.join(base_output_dir, f) \n",
    "    for f in concat_file_list\n",
    "}\n",
    "concat_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Composite Video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resizing Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "def resize_video(video_path, width, height, save_dir):\n",
    "    \"\"\"\n",
    "    Resize a video to the specified width and height using ffmpeg,\n",
    "    with debug‐level output.\n",
    "\n",
    "    Parameters:\n",
    "    - video_path: str, path to the input video file\n",
    "    - width: int, target width in pixels\n",
    "    - height: int, target height in pixels\n",
    "    - save_dir: str, directory where the resized video will be saved\n",
    "\n",
    "    The output filename will be: <original_basename>_<width>x<height>.mp4\n",
    "    \"\"\"\n",
    "    # Ensure the save directory exists\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # Derive output filename from input basename\n",
    "    base_name = os.path.splitext(os.path.basename(video_path))[0]\n",
    "    output_filename = f\"{base_name}.mp4\"   # f\"{base_name}_{width}x{height}.mp4\"\n",
    "    output_path = os.path.join(save_dir, output_filename)\n",
    "\n",
    "    # Build ffmpeg command with debug-level logging\n",
    "    cmd = [\n",
    "        \"ffmpeg\",\n",
    "        \"-y\",                   # overwrite output if it exists\n",
    "        \"-loglevel\", \"debug\",   # show full debug output\n",
    "        \"-i\", video_path,\n",
    "        \"-vf\", f\"scale={width}:{height}\",\n",
    "        \"-c:v\", \"libx264\",\n",
    "        \"-crf\", \"18\",\n",
    "        \"-preset\", \"slow\",\n",
    "        output_path\n",
    "    ]\n",
    "\n",
    "    # Run ffmpeg and capture stdout/stderr\n",
    "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "\n",
    "    # Print debug output\n",
    "    # print(\"=== ffmpeg stdout ===\")\n",
    "    # print(result.stdout)\n",
    "    # print(\"=== ffmpeg stderr ===\")\n",
    "    # print(result.stderr)\n",
    "\n",
    "    # Check return code and report\n",
    "    if result.returncode == 0:\n",
    "        print(f\"Resizing succeeded, output saved to: {output_path}\")\n",
    "    else:\n",
    "        print(f\"ffmpeg failed with return code {result.returncode}\")\n",
    "\n",
    "    return output_path if result.returncode == 0 else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_videos = {\n",
    "    'video_mix': concat_dict['video_mix'],  \n",
    "    'plot': concat_dict['plot'],    \n",
    "    'joint_Hips': concat_dict['joint_Hips'],\n",
    "    'drum_dot': concat_dict['drum_dot'],\n",
    "    'dance_dot': concat_dict['dance_dot'],\n",
    "    \n",
    "    'front_view': concat_dict['front_view'],\n",
    "    # 'left_view': concat_dict['left_view'],\n",
    "    # 'right_view': concat_dict['right_view'],\n",
    "    # 'top_view': concat_dict['top_view'],\n",
    "}\n",
    "\n",
    "canvas_w, canvas_h = 1920, 1080 \n",
    "composite_layout_1 = [\n",
    "    # Top row - side by side\n",
    "    {'view': 'video_mix', 'x': 0, 'y': 0, 'width': 960, 'height': 540},\n",
    "    {'view': 'front_view', 'x': 960, 'y': 0, 'width': 960, 'height': 540},\n",
    "    \n",
    "    # Bottom row - stacked vertically\n",
    "    {'view': 'joint_Hips', 'x': 0, 'y': 540, 'width': 1920, 'height': 270},\n",
    "    {'view': 'plot', 'x': 0, 'y': 810, 'width': 1920, 'height': 270},\n",
    "]\n",
    "\n",
    "composite_layout_2 = [\n",
    "    # Top row - side by side\n",
    "    {'view': 'video_mix', 'x': 0, 'y': 0, 'width': 960, 'height': 540},\n",
    "    {'view': 'front_view', 'x': 960, 'y': 0, 'width': 960, 'height': 540},\n",
    "    \n",
    "    # Bottom row - stacked vertically\n",
    "    {'view': 'joint_Hips', 'x': 0, 'y': 540, 'width': 960, 'height': 270},\n",
    "    {'view': 'plot', 'x': 0, 'y': 810, 'width': 960, 'height': 270},\n",
    "    \n",
    "    # {'view': 'drum_dot', 'x': 960, 'y': 540, 'width': 960, 'height': 540},\n",
    "    {'view': 'drum_dot', 'x': 960, 'y': 540, 'width': 960, 'height': 270},\n",
    "    {'view': 'dance_dot', 'x': 960, 'y': 810, 'width': 960, 'height': 270},\n",
    "]\n",
    "\n",
    "\n",
    "saved_resized_dir = os.path.join(base_output_dir, \"temp_resized\")\n",
    "os.makedirs(saved_resized_dir, exist_ok=True)\n",
    "\n",
    "composite_video_elements = []\n",
    "\n",
    "for video_element in composite_layout_2:\n",
    "    video_path = view_videos[video_element['view']]\n",
    "    v_width, v_height = video_element['width'], video_element['height']\n",
    "    x_pos_pxl, y_pos_pxl = video_element['x'], video_element['y']\n",
    "    \n",
    "    resized_path = resize_video(video_path, v_width, v_height, saved_resized_dir)\n",
    "    \n",
    "    composite_video_elements.append({\"view\": video_element['view'], \n",
    "                           \"vid_path\": resized_path,\n",
    "                           \"x_pos_pxl\": x_pos_pxl,\n",
    "                           \"y_pos_pxl\": y_pos_pxl,\n",
    "                           })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of dictionaries with just the paths and positions\n",
    "video_positions = []\n",
    "for element in composite_video_elements:\n",
    "    video_positions.append({\n",
    "        'path': element['vid_path'],\n",
    "        'x': element['x_pos_pxl'],\n",
    "        'y': element['y_pos_pxl']\n",
    "    })\n",
    "\n",
    "# Build the ffmpeg command\n",
    "ffmpeg_inputs = []\n",
    "for pos in video_positions:\n",
    "    ffmpeg_inputs.extend(['-i', pos['path']])\n",
    "\n",
    "# Create the xstack layout string\n",
    "# Format: xstack=inputs=4:layout=0_0|w0_0|0_h0|w0_h0\n",
    "layout = []\n",
    "for pos in video_positions:\n",
    "    layout.append(f\"{pos['x']}_{pos['y']}\")\n",
    "\n",
    "xstack_layout = \"|\".join(layout)\n",
    "\n",
    "final_out = os.path.join(base_output_dir, f\"{file_name}_{start_time:.2f}_{end_time:.2f}.mp4\")\n",
    "ffmpeg_cmd = [\n",
    "    'ffmpeg', '-y',\n",
    "    *ffmpeg_inputs,\n",
    "    '-filter_complex', f'xstack=inputs={len(video_positions)}:layout={xstack_layout}[v]',\n",
    "    '-map', '[v]',\n",
    "    '-map', '0:a?', '-c:a', 'aac', '-b:a', '192k',\n",
    "    '-c:v', 'libx264',   #'libx264',\n",
    "    '-crf', '23',\n",
    "    '-preset', 'ultrafast',\n",
    "    final_out\n",
    "]\n",
    "\n",
    "# Execute the command\n",
    "\n",
    "try:\n",
    "    subprocess.run(ffmpeg_cmd, check=True)\n",
    "    print(f\"Video successfully created as {final_out}\")\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"Error creating video: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
