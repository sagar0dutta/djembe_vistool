{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "# from utils_subdivision.gen_distribution_single_plots import analyze_phases\n",
    "# from utils_subdivision.gen_distribution_subplot import analyze_single_type    # plot_combined_results\n",
    "# from utils_subdivision.gen_distribution_merged_plot import plot_merged\n",
    "from utils_dot_plot.drum_single import analyze_phases\n",
    "# from utils_dot_plot.drum_merged import plot_merged_per_mode\n",
    "\n",
    "from utils_subdivision.gen_distribution_subplot import analyze_single_type\n",
    "from utils_dot_plot.kinematic_dot_plot import *\n",
    "from utils_dot_plot.drum_merged import *\n",
    "\n",
    "\n",
    "base_output_dir = \"output_dot_plots\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Dance dot plot by Group, Individual or Audience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_idx = 0\n",
    "mode = [\"group\", \"individual\", \"audience\"]\n",
    "dance_mode = mode[m_idx]\n",
    "\n",
    "with open('data/selected_piece_list.pkl', 'rb') as f:\n",
    "    piece_list = pickle.load(f)\n",
    "    \n",
    "for file_name in piece_list:\n",
    "    print(file_name)\n",
    "    cycles_csv_path = f\"data/virtual_cycles/{file_name}_C.csv\"\n",
    "    \n",
    "    dmode_path = f\"data/dance_modes_ts/{file_name}_{dance_mode}.pkl\"\n",
    "    if not os.path.exists(dmode_path):\n",
    "        continue\n",
    "    \n",
    "    left_onset_path = f\"data/logs_v4_0.007_foot_jun3/{file_name}_T/onset_info/{file_name}_T_left_foot_onsets.csv\"\n",
    "    right_onset_path = f\"data/logs_v4_0.007_foot_jun3/{file_name}_T/onset_info/{file_name}_T_right_foot_onsets.csv\"\n",
    "    \n",
    "    left_onsets = pd.read_csv(left_onset_path)[\"time_sec\"].values\n",
    "    right_onsets = pd.read_csv(right_onset_path)[\"time_sec\"].values\n",
    "    \n",
    "    if os.path.exists(dmode_path):\n",
    "        with open(dmode_path, \"rb\") as f:\n",
    "            dance_mode_time_segments = pickle.load(f)\n",
    "            \n",
    "        fig, ax, _ = plot_foot_onsets_stacked(\n",
    "            file_name=file_name,\n",
    "            dance_mode=dance_mode,\n",
    "            cycles_csv_path=cycles_csv_path,\n",
    "            left_onsets=left_onsets,\n",
    "            right_onsets=right_onsets,\n",
    "            dance_mode_time_segments=dance_mode_time_segments,\n",
    "            figsize=(10, 3),\n",
    "            dpi=200,\n",
    "            use_window=True,\n",
    "            legend_flag=False\n",
    "        )\n",
    "        \n",
    "        save_dir = os.path.join(base_output_dir, \"dance\", dance_mode)\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        \n",
    "        save_path = os.path.join(save_dir, f\"{file_name}_{dance_mode}_merged.png\")\n",
    "        plt.savefig(save_path, bbox_inches='tight')  # Add bbox_inches='tight' to prevent label clipping\n",
    "        plt.close()\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merged Drum Dot Plot - All modes combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_merged_stacked_all_modes(\n",
    "    file_name,\n",
    "    cycles_csv_path,\n",
    "    onsets_csv_path,\n",
    "    dance_mode_time_segments_all,  # Dictionary containing time segments for all modes\n",
    "    figsize=(10, 3),\n",
    "    dpi=200,\n",
    "    use_window=True,\n",
    "    legend_flag=True\n",
    "):\n",
    "    \"\"\"Create a single plot showing combined drum onset analysis for all modes for a single file.\"\"\"\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=figsize, dpi=dpi)\n",
    "    vertical_ranges = {\n",
    "        'Dun': (1, 6),\n",
    "        'J1': (8, 13),\n",
    "        'J2': (15, 20)\n",
    "    }\n",
    "\n",
    "    # Fixed colors for each drum type\n",
    "    drum_colors = {\n",
    "        'Dun': '#1f77b4',   # blue\n",
    "        'J1': '#d62728',    # red\n",
    "        'J2': '#2ca02c'     # green\n",
    "    }\n",
    "\n",
    "    # Initialize combined data structure\n",
    "    onset_types = ['Dun', 'J1', 'J2']\n",
    "    drum_phases_kde = {onset_type: {\"phases\": [], \"y_scaled\": []} for onset_type in onset_types}\n",
    "    \n",
    "    # Process each mode\n",
    "    for mode, dance_mode_time_segments in dance_mode_time_segments_all.items():\n",
    "        # Get cycles data\n",
    "        cycles_df = pd.read_csv(cycles_csv_path)\n",
    "        cycle_times = cycles_df['Virtual Onset'].values\n",
    "        \n",
    "        # Get onsets data\n",
    "        onsets_df = pd.read_csv(onsets_csv_path)\n",
    "        \n",
    "        # Process each onset type\n",
    "        for onset_type in onset_types:\n",
    "            # Get onset times for this type\n",
    "            onset_times = onsets_df[onset_type].dropna().values  # Remove NaN values\n",
    "            \n",
    "            # Process each time segment\n",
    "            for segment in dance_mode_time_segments:\n",
    "                start_time, end_time = segment  # Unpack the tuple\n",
    "                \n",
    "                # Get cycles in this segment\n",
    "                segment_cycles = cycle_times[\n",
    "                    (cycle_times >= start_time) & \n",
    "                    (cycle_times <= end_time)\n",
    "                ]\n",
    "                \n",
    "                if len(segment_cycles) == 0:\n",
    "                    continue\n",
    "                \n",
    "                # Get onsets in this segment\n",
    "                segment_onsets = onset_times[\n",
    "                    (onset_times >= start_time) & \n",
    "                    (onset_times <= end_time)\n",
    "                ]\n",
    "                \n",
    "                if len(segment_onsets) == 0:\n",
    "                    continue\n",
    "                \n",
    "                # Calculate phases for each onset\n",
    "                for onset_time in segment_onsets:\n",
    "                    # Find the cycle containing this onset\n",
    "                    cycle_mask = (cycle_times <= onset_time)\n",
    "                    if not any(cycle_mask):\n",
    "                        continue\n",
    "                    \n",
    "                    cycle_start = cycle_times[cycle_mask][-1]  # Last cycle before onset\n",
    "                    \n",
    "                    # Find the next cycle\n",
    "                    next_cycle_mask = (cycle_times > onset_time)\n",
    "                    if any(next_cycle_mask):\n",
    "                        cycle_end = cycle_times[next_cycle_mask][0]\n",
    "                    else:\n",
    "                        cycle_end = cycle_times[-1]\n",
    "                    \n",
    "                    # Calculate phase\n",
    "                    phase = (onset_time - cycle_start) / (cycle_end - cycle_start)\n",
    "                    \n",
    "                    # Handle cycle wrapping\n",
    "                    if phase > 0.98:  # If phase is closer to next cycle\n",
    "                        phase = phase - 1.0\n",
    "                    \n",
    "                    # Add to combined data\n",
    "                    drum_phases_kde[onset_type][\"phases\"].append(phase)\n",
    "                    drum_phases_kde[onset_type][\"y_scaled\"].append(len(drum_phases_kde[onset_type][\"phases\"]))\n",
    "\n",
    "    # Plot the combined data\n",
    "    for onset_type, color in drum_colors.items():\n",
    "        phases = np.array(drum_phases_kde[onset_type][\"phases\"])\n",
    "        y_scaled = np.array(drum_phases_kde[onset_type][\"y_scaled\"])\n",
    "        \n",
    "        if len(phases) == 0:\n",
    "            continue\n",
    "            \n",
    "        # Normalize y_scaled values to fit within the vertical range\n",
    "        y_min, y_max = vertical_ranges[onset_type]\n",
    "        y_scaled = y_min + (y_scaled - np.min(y_scaled)) * (y_max - y_min) / (np.max(y_scaled) - np.min(y_scaled))\n",
    "        \n",
    "        # Plot scatter\n",
    "        ax.scatter(phases * 400,\n",
    "                  y_scaled,\n",
    "                  s=5, alpha=0.4,\n",
    "                  color=color,\n",
    "                  label=f'{onset_type}')\n",
    "\n",
    "    # Calculate and plot combined KDE\n",
    "    all_phases = []\n",
    "    for onset_type in onset_types:\n",
    "        all_phases.extend(drum_phases_kde[onset_type][\"phases\"])\n",
    "    \n",
    "    if len(all_phases) > 0:\n",
    "        kde_xx, kde_h = kde_estimate(np.array(all_phases), SIG=0.01)\n",
    "        \n",
    "        # Only plot the region that maps to the x-axis\n",
    "        mask = (kde_xx * 400 >= -33) & (kde_xx * 400 <= 400)\n",
    "        kde_xx_plot = kde_xx[mask]\n",
    "        kde_h_plot = kde_h[mask]\n",
    "        \n",
    "        if np.max(kde_h_plot) > 0:\n",
    "            kde_scaled = -5 + (5 * kde_h_plot / np.max(kde_h_plot))\n",
    "            ax.fill_between(kde_xx_plot * 400, -5, kde_scaled, alpha=0.3, color='purple', label='Combined KDE')\n",
    "\n",
    "    # Subdivision lines\n",
    "    for subdiv in range(1, 13):\n",
    "        color = get_subdiv_color(subdiv)\n",
    "        x_pos = ((subdiv-1) * 400) / 12\n",
    "        \n",
    "        if subdiv in [1, 4, 7, 10]:\n",
    "            ax.vlines(x_pos, -5.5, 20.5, color=color, linestyle='-', linewidth=1.5, alpha=0.7)\n",
    "        else:\n",
    "            ax.vlines(x_pos, -5.5, 20.5, color=color, linestyle='--', linewidth=1, alpha=0.3)\n",
    "\n",
    "    # Styling\n",
    "    xtick = [0, 100, 200, 300, 400]\n",
    "    xtick_labels = [1, 2, 3, 4, 5]\n",
    "    \n",
    "    ax.set_xticks(xtick)\n",
    "    ax.set_xticklabels(xtick_labels)\n",
    "    ax.set_xlim(-33, 400)\n",
    "    ax.set_xlabel('Beat span')\n",
    "    \n",
    "    ax.set_ylim(-5.5, 20.5)\n",
    "    ax.set_yticks([3, 10, 17])\n",
    "    ax.set_yticklabels(['Dun', 'J1', 'J2'])\n",
    "    ax.set_ylabel('Drum')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    # Title & legend\n",
    "    title = f'File: {file_name} | All Modes Combined'\n",
    "    # title += f' | Combined from {len(dance_mode_time_segments_all)} modes'\n",
    "    ax.set_title(title, pad=10)\n",
    "    \n",
    "    if legend_flag:\n",
    "        ax.legend(loc='upper left', framealpha=0.4, fontsize=6)\n",
    "\n",
    "    return fig, ax, drum_phases_kde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the piece list\n",
    "with open('data/selected_piece_list.pkl', 'rb') as f:\n",
    "    piece_list = pickle.load(f)\n",
    "\n",
    "# Loop over each file in the piece list\n",
    "for file_name in piece_list:\n",
    "    print(f\"Processing {file_name}...\")\n",
    "    \n",
    "    # Define paths\n",
    "    cycles_csv_path = f\"data/virtual_cycles/{file_name}_C.csv\"\n",
    "    onsets_csv_path = f\"data/drum_onsets/{file_name}.csv\"\n",
    "    \n",
    "    # Check if required files exist\n",
    "    if not (os.path.exists(cycles_csv_path) and os.path.exists(onsets_csv_path)):\n",
    "        print(f\"Skipping {file_name} - missing required files\")\n",
    "        continue\n",
    "    \n",
    "    # Load all modes' time segments\n",
    "    dance_mode_time_segments_all = {}\n",
    "    for mode in [\"group\", \"individual\", \"audience\"]:\n",
    "        dmode_path = f\"data/dance_modes_ts/{file_name}_{mode}.pkl\"\n",
    "        if os.path.exists(dmode_path):\n",
    "            with open(dmode_path, \"rb\") as f:\n",
    "                dance_mode_time_segments_all[mode] = pickle.load(f)\n",
    "    \n",
    "    # Skip if no mode data available\n",
    "    if not dance_mode_time_segments_all:\n",
    "        print(f\"Skipping {file_name} - no mode data available\")\n",
    "        continue\n",
    "    \n",
    "    # try:\n",
    "    # Call the modified function\n",
    "    fig, ax, drum_phases_kde = plot_merged_stacked_all_modes(\n",
    "        file_name=file_name,\n",
    "        cycles_csv_path=cycles_csv_path,\n",
    "        onsets_csv_path=onsets_csv_path,\n",
    "        dance_mode_time_segments_all=dance_mode_time_segments_all,\n",
    "        figsize=(10, 3),\n",
    "        dpi=200,\n",
    "        use_window=True,\n",
    "        legend_flag=False\n",
    "    )\n",
    "    \n",
    "    # Save the figure\n",
    "    save_dir = os.path.join(base_output_dir, \"drum_merged\", \"all_modes\")\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    save_path = os.path.join(save_dir, f\"{file_name}_all_modes_merged.png\")\n",
    "    plt.savefig(save_path, bbox_inches='tight', dpi=200)\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"Successfully processed {file_name}\")\n",
    "        \n",
    "    # except Exception as e:\n",
    "    #     print(f\"Error processing {file_name}: {str(e)}\")\n",
    "    #     continue\n",
    "\n",
    "print(\"Processing complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dance dot plot - All modes combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_foot_onsets_stacked_all_modes(\n",
    "    file_name,\n",
    "    cycles_csv_path,\n",
    "    left_onset_path,\n",
    "    right_onset_path,\n",
    "    dance_mode_time_segments_all,  # Dictionary containing time segments for all modes\n",
    "    figsize=(10, 3),\n",
    "    dpi=200,\n",
    "    use_window=True,\n",
    "    legend_flag=True\n",
    "):\n",
    "    \"\"\"Create a single plot showing combined foot onset analysis for all modes for a single file.\"\"\"\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=figsize, dpi=dpi)\n",
    "    vertical_ranges = {\n",
    "        'left': (1, 6),\n",
    "        'right': (8, 13)\n",
    "    }\n",
    "\n",
    "    # Fixed colors for feet\n",
    "    foot_colors = {\n",
    "        'left': '#1f77b4',   # blue\n",
    "        'right': '#d62728'   # red\n",
    "    }\n",
    "\n",
    "    # Initialize combined data structure\n",
    "    foot_types = ['left', 'right']\n",
    "    foot_phases_kde = {foot_type: {\"phases\": [], \"y_scaled\": []} for foot_type in foot_types}\n",
    "    \n",
    "    # Load foot onset data\n",
    "    left_onsets = pd.read_csv(left_onset_path)[\"time_sec\"].values\n",
    "    right_onsets = pd.read_csv(right_onset_path)[\"time_sec\"].values\n",
    "    \n",
    "    # Process each mode\n",
    "    for mode, dance_mode_time_segments in dance_mode_time_segments_all.items():\n",
    "        # Get cycles data\n",
    "        cycles_df = pd.read_csv(cycles_csv_path)\n",
    "        cycle_times = cycles_df['Virtual Onset'].values\n",
    "        \n",
    "        # Process each foot type\n",
    "        for foot_type, color in foot_colors.items():\n",
    "            # Get onset times for this foot\n",
    "            onset_times = left_onsets if foot_type == 'left' else right_onsets\n",
    "            \n",
    "            # Process each time segment\n",
    "            for segment in dance_mode_time_segments:\n",
    "                start_time, end_time = segment  # Unpack the tuple\n",
    "                \n",
    "                # Get cycles in this segment\n",
    "                segment_cycles = cycle_times[\n",
    "                    (cycle_times >= start_time) & \n",
    "                    (cycle_times <= end_time)\n",
    "                ]\n",
    "                \n",
    "                if len(segment_cycles) == 0:\n",
    "                    continue\n",
    "                \n",
    "                # Get onsets in this segment\n",
    "                segment_onsets = onset_times[\n",
    "                    (onset_times >= start_time) & \n",
    "                    (onset_times <= end_time)\n",
    "                ]\n",
    "                \n",
    "                if len(segment_onsets) == 0:\n",
    "                    continue\n",
    "                \n",
    "                # Calculate phases for each onset\n",
    "                for onset_time in segment_onsets:\n",
    "                    # Find the cycle containing this onset\n",
    "                    cycle_mask = (cycle_times <= onset_time)\n",
    "                    if not any(cycle_mask):\n",
    "                        continue\n",
    "                    \n",
    "                    cycle_start = cycle_times[cycle_mask][-1]  # Last cycle before onset\n",
    "                    \n",
    "                    # Find the next cycle\n",
    "                    next_cycle_mask = (cycle_times > onset_time)\n",
    "                    if any(next_cycle_mask):\n",
    "                        cycle_end = cycle_times[next_cycle_mask][0]\n",
    "                    else:\n",
    "                        cycle_end = cycle_times[-1]\n",
    "                    \n",
    "                    # Skip if cycle_start equals cycle_end\n",
    "                    if cycle_end == cycle_start:\n",
    "                        continue\n",
    "                    \n",
    "                    # Calculate phase\n",
    "                    phase = (onset_time - cycle_start) / (cycle_end - cycle_start)\n",
    "                    \n",
    "                    # Handle cycle wrapping\n",
    "                    # if phase > 0.5:  # If phase is closer to next cycle\n",
    "                    #     phase = phase - 1.0\n",
    "                    \n",
    "                    # Add to combined data\n",
    "                    foot_phases_kde[foot_type][\"phases\"].append(phase)\n",
    "                    foot_phases_kde[foot_type][\"y_scaled\"].append(len(foot_phases_kde[foot_type][\"phases\"]))\n",
    "\n",
    "    # Plot the combined data\n",
    "    for foot_type, color in foot_colors.items():\n",
    "        phases = np.array(foot_phases_kde[foot_type][\"phases\"])\n",
    "        y_scaled = np.array(foot_phases_kde[foot_type][\"y_scaled\"])\n",
    "        \n",
    "        if len(phases) == 0:\n",
    "            continue\n",
    "            \n",
    "        # Normalize y_scaled values to fit within the vertical range\n",
    "        y_min, y_max = vertical_ranges[foot_type]\n",
    "        y_scaled = y_min + (y_scaled - np.min(y_scaled)) * (y_max - y_min) / (np.max(y_scaled) - np.min(y_scaled))\n",
    "    \n",
    "        # Plot scatter\n",
    "        ax.scatter(phases * 400,\n",
    "                  y_scaled,\n",
    "                  s=5, alpha=0.4,\n",
    "                  color=color,\n",
    "                  label=f'{foot_type.capitalize()} Foot')\n",
    "\n",
    "    # Calculate and plot combined KDE\n",
    "    all_phases = []\n",
    "    for foot_type in foot_types:\n",
    "        all_phases.extend(foot_phases_kde[foot_type][\"phases\"])\n",
    "    \n",
    "    if len(all_phases) > 0:\n",
    "        kde_xx, kde_h = kde_estimate(np.array(all_phases), SIG=0.01)\n",
    "        \n",
    "        # Only plot the region that maps to the x-axis\n",
    "        mask = (kde_xx * 400 >= -33) & (kde_xx * 400 <= 400)\n",
    "        kde_xx_plot = kde_xx[mask]\n",
    "        kde_h_plot = kde_h[mask]\n",
    "        \n",
    "        if np.max(kde_h_plot) > 0:\n",
    "            kde_scaled = -5 + (5 * kde_h_plot / np.max(kde_h_plot))\n",
    "            ax.fill_between(kde_xx_plot * 400, -5, kde_scaled, alpha=0.3, color='purple', label='Combined KDE')\n",
    "\n",
    "    # Subdivision lines\n",
    "    for subdiv in range(1, 13):\n",
    "        color = get_subdiv_color(subdiv)\n",
    "        x_pos = ((subdiv-1) * 400) / 12\n",
    "        \n",
    "        if subdiv in [1, 4, 7, 10]:\n",
    "            ax.vlines(x_pos, -5.5, 13.5, color=color, linestyle='-', linewidth=1.5, alpha=0.7)\n",
    "        else:\n",
    "            ax.vlines(x_pos, -5.5, 13.5, color=color, linestyle='--', linewidth=1, alpha=0.3)\n",
    "\n",
    "    # Styling\n",
    "    xtick = [0, 100, 200, 300, 400]\n",
    "    xtick_labels = [1, 2, 3, 4, 5]\n",
    "    \n",
    "    ax.set_xticks(xtick)\n",
    "    ax.set_xticklabels(xtick_labels)\n",
    "    ax.set_xlim(-33, 400)\n",
    "    ax.set_xlabel('Beat span')\n",
    "    \n",
    "    ax.set_ylim(-5.5, 13.5)\n",
    "    ax.set_yticks([3, 10])\n",
    "    ax.set_yticklabels(['LF', 'RF'])\n",
    "    ax.set_ylabel('Foot')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    # Title & legend\n",
    "    title = f'File: {file_name} | All Modes Combined'\n",
    "    # title += f' | Combined from {len(dance_mode_time_segments_all)} modes'\n",
    "    ax.set_title(title, pad=10)\n",
    "    \n",
    "    if legend_flag:\n",
    "        ax.legend(loc='upper left', framealpha=0.4, fontsize=6)\n",
    "\n",
    "    return fig, ax, foot_phases_kde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing BKO_E1_D1_01_Suku...\n",
      "Successfully processed BKO_E1_D1_01_Suku\n",
      "Processing BKO_E1_D1_02_Maraka...\n",
      "Successfully processed BKO_E1_D1_02_Maraka\n",
      "Processing BKO_E1_D1_03_Wasulunka...\n",
      "Successfully processed BKO_E1_D1_03_Wasulunka\n",
      "Processing BKO_E1_D1_06_Manjanin...\n",
      "Successfully processed BKO_E1_D1_06_Manjanin\n",
      "Processing BKO_E1_D1_07_Suku...\n",
      "Successfully processed BKO_E1_D1_07_Suku\n",
      "Processing BKO_E1_D1_08_Suku...\n",
      "Successfully processed BKO_E1_D1_08_Suku\n",
      "Processing BKO_E1_D2_03_Suku...\n",
      "Successfully processed BKO_E1_D2_03_Suku\n",
      "Processing BKO_E1_D2_04_Maraka...\n",
      "Successfully processed BKO_E1_D2_04_Maraka\n",
      "Processing BKO_E1_D2_05_Wasulunka...\n",
      "Successfully processed BKO_E1_D2_05_Wasulunka\n",
      "Processing BKO_E1_D5_01_Maraka...\n",
      "Successfully processed BKO_E1_D5_01_Maraka\n",
      "Processing BKO_E1_D5_04_Suku...\n",
      "Successfully processed BKO_E1_D5_04_Suku\n",
      "Processing BKO_E2_D3_01_Maraka...\n",
      "Successfully processed BKO_E2_D3_01_Maraka\n",
      "Processing BKO_E2_D3_02_Suku...\n",
      "Successfully processed BKO_E2_D3_02_Suku\n",
      "Processing BKO_E2_D3_03_Wasulunka...\n",
      "Successfully processed BKO_E2_D3_03_Wasulunka\n",
      "Processing BKO_E2_D3_06_Manjanin...\n",
      "Successfully processed BKO_E2_D3_06_Manjanin\n",
      "Processing BKO_E2_D3_11_Suku...\n",
      "Successfully processed BKO_E2_D3_11_Suku\n",
      "Processing BKO_E2_D3_13_Suku...\n",
      "Successfully processed BKO_E2_D3_13_Suku\n",
      "Processing BKO_E2_D3_14_Maraka...\n",
      "Successfully processed BKO_E2_D3_14_Maraka\n",
      "Processing BKO_E2_D4_01_Suku...\n",
      "Successfully processed BKO_E2_D4_01_Suku\n",
      "Processing BKO_E2_D4_02_Maraka...\n",
      "Successfully processed BKO_E2_D4_02_Maraka\n",
      "Processing BKO_E2_D4_03_Wasulunka...\n",
      "Successfully processed BKO_E2_D4_03_Wasulunka\n",
      "Processing BKO_E2_D4_06_Manjanin...\n",
      "Successfully processed BKO_E2_D4_06_Manjanin\n",
      "Processing BKO_E2_D4_12_Suku...\n",
      "Successfully processed BKO_E2_D4_12_Suku\n",
      "Processing BKO_E3_D5_01_Maraka...\n",
      "Successfully processed BKO_E3_D5_01_Maraka\n",
      "Processing BKO_E3_D5_02_Suku...\n",
      "Successfully processed BKO_E3_D5_02_Suku\n",
      "Processing BKO_E3_D5_03_Wasulunka...\n",
      "Successfully processed BKO_E3_D5_03_Wasulunka\n",
      "Processing BKO_E3_D5_06_Manjanin...\n",
      "Successfully processed BKO_E3_D5_06_Manjanin\n",
      "Processing BKO_E3_D5_13_Suku...\n",
      "Successfully processed BKO_E3_D5_13_Suku\n",
      "Processing BKO_E3_D6_01_Maraka...\n",
      "Successfully processed BKO_E3_D6_01_Maraka\n",
      "Processing BKO_E3_D6_02_Suku...\n",
      "Successfully processed BKO_E3_D6_02_Suku\n",
      "Processing BKO_E3_D6_03_Wasulunka...\n",
      "Successfully processed BKO_E3_D6_03_Wasulunka\n",
      "Processing BKO_E3_D6_06_Manjanin...\n",
      "Successfully processed BKO_E3_D6_06_Manjanin\n",
      "Processing BKO_E3_D6_12_Suku...\n",
      "Successfully processed BKO_E3_D6_12_Suku\n",
      "Processing complete!\n"
     ]
    }
   ],
   "source": [
    "# Load the piece list\n",
    "with open('data/selected_piece_list.pkl', 'rb') as f:\n",
    "    piece_list = pickle.load(f)\n",
    "\n",
    "# Loop over each file in the piece list\n",
    "for file_name in piece_list:\n",
    "    print(f\"Processing {file_name}...\")\n",
    "    \n",
    "    # Define paths\n",
    "    cycles_csv_path = f\"data/virtual_cycles/{file_name}_C.csv\"\n",
    "    left_onset_path = f\"data/logs_v4_0.007_foot_jun3/{file_name}_T/onset_info/{file_name}_T_left_foot_onsets.csv\"\n",
    "    right_onset_path = f\"data/logs_v4_0.007_foot_jun3/{file_name}_T/onset_info/{file_name}_T_right_foot_onsets.csv\"\n",
    "    \n",
    "    # Check if required files exist\n",
    "    if not (os.path.exists(cycles_csv_path) and \n",
    "            os.path.exists(left_onset_path) and \n",
    "            os.path.exists(right_onset_path)):\n",
    "        print(f\"Skipping {file_name} - missing required files\")\n",
    "        continue\n",
    "    \n",
    "    # Load all modes' time segments\n",
    "    dance_mode_time_segments_all = {}\n",
    "    for mode in [\"group\", \"individual\", \"audience\"]:\n",
    "        dmode_path = f\"data/dance_modes_ts/{file_name}_{mode}.pkl\"\n",
    "        if os.path.exists(dmode_path):\n",
    "            with open(dmode_path, \"rb\") as f:\n",
    "                dance_mode_time_segments_all[mode] = pickle.load(f)\n",
    "    \n",
    "    # Skip if no mode data available\n",
    "    if not dance_mode_time_segments_all:\n",
    "        print(f\"Skipping {file_name} - no mode data available\")\n",
    "        continue\n",
    "    \n",
    "\n",
    "    # Call the modified function\n",
    "    fig, ax, foot_phases_kde = plot_foot_onsets_stacked_all_modes(\n",
    "        file_name=file_name,\n",
    "        cycles_csv_path=cycles_csv_path,\n",
    "        left_onset_path=left_onset_path,\n",
    "        right_onset_path=right_onset_path,\n",
    "        dance_mode_time_segments_all=dance_mode_time_segments_all,\n",
    "        figsize=(10, 3),\n",
    "        dpi=200,\n",
    "        use_window=True,\n",
    "        legend_flag=False\n",
    "    )\n",
    "    \n",
    "    # Save the figure\n",
    "    save_dir = os.path.join(base_output_dir, \"dance\", \"all_modes\")\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    save_path = os.path.join(save_dir, f\"{file_name}_all_modes_merged.png\")\n",
    "    plt.savefig(save_path, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"Successfully processed {file_name}\")\n",
    "        \n",
    "\n",
    "\n",
    "print(\"Processing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
